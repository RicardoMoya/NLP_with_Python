{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Conceptos para el Procesamiento del Lenguaje Natural con spaCy\n",
    "\n",
    "* ***spaCy*** es una librería de código abierto en python para el Procesamiento del Lenguaje natural que posee modelos entrenados para varios idiomas, entre ellos el Español.\n",
    "\n",
    "\n",
    "* Es una librería pensada para funcionar en entornos productivos y es una librería con mejor rendimiento que **NLTK**.\n",
    "\n",
    "\n",
    "* Dispone de una web y de una documentación muy buena, incluso se pueden ejecutar ciertos ejemplos en la propia web: https://spacy.io/\n",
    "\n",
    "\n",
    "* Dispone también de un curso online (https://course.spacy.io/) bastante interesante.\n",
    "\n",
    "\n",
    "* Entre otras cosas con ***spaCy*** podemos hacer:\n",
    "    1. Tokenización\n",
    "    2. Lematización\n",
    "    3. Detección de Stop Words\n",
    "    4. Part of Speech (PoS)\n",
    "    5. Named Entity Recognition (NER)\n",
    "\n",
    "\n",
    "* ***spaCy*** puede ser instalado tanto con \"pip\" como con \"conda\" de la siguiente manera respectivamente:\n",
    "\n",
    "```\n",
    ">> pip install spacy\n",
    ">> conda install spacy\n",
    "```\n",
    "\n",
    "\n",
    "* Como se ha comentado anteriormente la ventaja que tiene ***spaCy*** frente a ***NLTK*** en lo que a idiomas se refiere es que permite trabajar con varior idiomas gracias a los modelos que tiene entrenados.\n",
    "\n",
    "\n",
    "* En particular para el Español ***spaCy*** tiene entrenados dos modelos (con Redes Neuronales Convolucionales según su documentación) de pequeño y mediano tamaño con los corpus de **AnCora** (http://clic.ub.edu/corpus/es/ancora) y **WikiNER**.\n",
    "\n",
    "\n",
    "* Estos dos modelos de pequeño y mediano tamaño los podemos encontrar en la web de ***spaCy*** (https://spacy.io/models/es) y son los siguiente:\n",
    "    - es_core_news_md (93 MiB)\n",
    "    - es_core_news_sm (35 MiB)\n",
    "\n",
    "\n",
    "* ***spaCy*** hace uso de estos modelos y tienen que ser descargados, para ello debemos de abrir un terminal en python y ejecutar lo siguiente para descargar el modelo en Español (*NOTA: los que uséis conda, tener activado el entorno*).\n",
    "\n",
    "\n",
    "```\n",
    ">> python3 -m spacy download es\n",
    "```\n",
    "\n",
    "\n",
    "<img src=\"./imgs/005_spacy_es_download.png\" style=\"width: 500px;\"/>\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "# spaCy - Arquitectura:\n",
    "\n",
    "* ***spaCy*** utiliza dos tipos de estructuras (objetos) llamados **Doc** y **Vocab**:\n",
    "\n",
    "    - ***Doc***: Este objeto esta formado por una secuencia de Tokens (objetos de la clase ***Token***).\n",
    "    - ***Vocab***: Este objeto posee un conjunto de Look-up tables (tablas de consulta) que hacen que la información común esté disponible en todos los documentos (Lemas, Stop Words, PoS, etc.).\n",
    "\n",
    "<img src=\"./imgs/006_spacy_architecture.png\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n",
    "* Una forma sencilla de trabajar con ***spaCy*** es:\n",
    "    1. Cargar un modelo de lenguaje (por ejemplo el Español)\n",
    "    2. Dado un texto plano, crear un objeto de la clase \"Doc\" y pasarle el texto plano. El texto ya quedará tokenizado dentro del objeto \"Doc\".\n",
    "    3. Trabajar sobre las palabras del documento.\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "\n",
    "# Ejemplos con spaCy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -Tokenización\n",
    "\n",
    "* Divide las cadenas de texto del documento en piezas más pequeñas o tokens.\n",
    "* Pasos:\n",
    "    1. Importar la librería.\n",
    "    2. Cargar un modelo de lenguaje (el Español).\n",
    "    3. Crear un documento (de la clase \"Doc\") pasándole un texto plano.\n",
    "    4. El objeto de la clase \"Doc\" ya esta tokenizado por palabras y podemos iterar sobre él."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo de dato: <class 'spacy.tokens.doc.Doc'>\n",
      "['Un', 'radar', 'multa', 'a', 'Mariano', '.', 'Rajoy', 'por', 'caminar', 'demasiado', 'rápido']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "doc = nlp(\"Un radar multa a Mariano. Rajoy por caminar demasiado rápido\")\n",
    "print('Tipo de dato: ' + str(type(doc)))\n",
    "print([w.text for w in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -Segmentación\n",
    "\n",
    "* La ***segmentación*** divide las cadenas de texto en frases o párrafos.\n",
    "* Para la segmentación en spaCy hay que usar un componente llamado \"**sentencier**\" que divide los textos por simbolos como puntos, interrogantes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Frase numero 1.', 'Frase número 2?', 'Frase 3']\n"
     ]
    }
   ],
   "source": [
    "sentencizer = nlp.create_pipe(\"sentencizer\")\n",
    "nlp.add_pipe(sentencizer)\n",
    "doc = nlp(\"Frase numero 1. Frase número 2? Frase 3\")\n",
    "print([s.text for s in doc.sents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -Stemming\n",
    "\n",
    "* ***Funcionalidad no disponoble en spaCy***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -Lematización\n",
    "\n",
    "* Proceso lingüístico que sustituye una palabra con forma flexionada (plurales, femeninos, verbos conjugados, etc.) por su lema; es decir, por una palabra válida en el idioma.\n",
    "* ***spaCy*** hace una lematización muy buena en Español.\n",
    "* Los objetos de la clase ***Token*** tienen la propiedad (o atributo) ***lema_*** que nos devuelve el lema del token (o la palabra)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unos - Unos\n",
      "radares - radar\n",
      "multan - multar\n",
      "a - a\n",
      "Mariano - Mariano\n",
      "Rajoy - Rajoy\n",
      "por - por\n",
      "ir - ir\n",
      "caminando - caminar\n",
      "demasiados - demasiar\n",
      "rápidos - rápido\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Unos radares multan a Mariano Rajoy por ir caminando demasiados rápidos\")\n",
    "for word in doc:  \n",
    "    print(word.text + ' - ' + word.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -Stop words\n",
    "\n",
    "* Son las palabras que no aportan nada al significado de la frase.\n",
    "* spaCy dispone de más de 500 stop words en Español.\n",
    "* Veamos a continuación las Stop Words en Español."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de stop words: 551\n",
      "Stop words: ['podrian', 'fin', 'tal', 'nuestra', 'unas', 'más', 'supuesto', 'de', 'nosotros', 'mucha', 'da', 'primer', 'sin', 'ese', 'bajo', 'tercera', 'principalmente', 'sido', 'vaya', 'ahi', 'el', 'habia', 'buena', 'un', 'demasiado', 'tenía', 'ambos', 'indicó', 'mí', 'últimos', 'he', 'segunda', 'le', 'me', 'sera', 'claro', 'igual', 'podría', 'los', 'tienen', 'primera', 'informo', 'ninguno', 'podriamos', 'tanto', 'pocas', 'hacer', 'cierta', 'ahora', 'estoy', 'haceis', 'tarde', 'ex', 'mio', 'varios', 'buenas', 'aquélla', 'hago', 'yo', 'hacerlo', 'podriais', 'va', 'pais', 'propios', 'podrán', 'usais', 'éstas', 'ciertos', 'temprano', 'sigue', 'misma', 'ninguna', 'última', 'del', 'fuimos', 'toda', 'mal', 'ver', 'cuales', 'cuánta', 'hasta', 'para', 'momento', 'son', 'modo', 'habrá', 'tuyo', 'teneis', 'hace', 'han', 'delante', 'debajo', 'ti', 'poder', 'contra', 'dan', 'fui', 'podemos', 'puedo', 'eran', 'usa', 'estado', 'poca', 'tampoco', 'buenos', 'sobre', 'mencionó', 'aquéllas', 'consigue', 'conocer', 'pues', 'considera', 'partir', 'podrían', 'intento', 'excepto', 'aquellos', 'llevar', 'ante', 'cuándo', 'conseguir', 'quizas', 'pronto', 'adrede', 'aun', 'nunca', 'poner', 'tengo', 'habla', 'bastante', 'quienes', 'final', 'varias', 'dado', 'aqui', 'usted', 'desde', 'siguiente', 'alguna', 'pasada', 'uno', 'debe', 'según', 'con', 'intentamos', 'somos', 'ustedes', 'afirmó', 'unos', 'además', 'estamos', 'nuestro', 'dicho', 'sabemos', 'ultimo', 'bien', 'todos', 'primero', 'nos', 'pueda', 'nuevas', 'era', 'cada', 'dos', 'realizado', 'se', 'cuanta', 'sois', 'casi', 'nada', 'dar', 'quiénes', 'saben', 'este', 'lo', 'suyas', 'deben', 'cuánto', 'deprisa', 'trabajamos', 'general', 'podrias', 'creo', 'intentas', 'realizó', 'antaño', 'cuanto', 'queremos', 'vamos', 'ya', 'alrededor', 'incluso', 'mios', 'cierto', 'hacia', 'conseguimos', 'dicen', 'usar', 'qué', 'medio', 'así', 'pueden', 'trabajo', 'debido', 'quedó', 'es', 'realizar', 'tiene', 'últimas', 'al', 'ello', 'demás', 'usan', 'último', 'contigo', 'conmigo', 'proximo', 'algo', 'nueva', 'qeu', 'despues', 'nuestras', 'aquellas', 'serán', 'soy', 'sola', 'quiere', 'tendrá', 'pocos', 'ése', 'ahí', 'solos', 'señaló', 'algunas', 'detrás', 'intenta', 'llegó', 'ser', 'ejemplo', 'dio', 'salvo', 'tuvo', 'informó', 'ningunos', 'mismos', 'dónde', 'suyo', 'consigues', 'cualquier', 'eramos', 'sus', 'algún', 'despacio', 'dice', 'antes', 'sea', 'antano', 'respecto', 'tan', 'lugar', 'consigo', 'peor', 'él', 'aquella', 'explicó', 'dijo', 'otro', 'en', 'su', 'sé', 'trabajan', 'cuantos', 'eres', 'vuestros', 'mío', 'la', 'como', 'propio', 'allí', 'esos', 'horas', 'aquello', 'aseguró', 'lado', 'parece', 'sabes', 'raras', 'agregó', 'solamente', 'que', 'fue', 'pero', 'uso', 'míos', 'mayor', 'aquel', 'verdadero', 'estar', 'aún', 'estados', 'vosotras', 'adelante', 'ir', 'aquéllos', 'enseguida', 'vosotros', 'quizás', 'siendo', 'tambien', 'dia', 'día', 'tú', 'mi', 'hacen', 'intentan', 'hecho', 'añadió', 'ésas', 'esas', 'mías', 'te', 'existe', 'ademas', 'todavía', 'pudo', 'vuestra', 'nadie', 'suya', 'gueno', 'cinco', 'dijeron', 'mismas', 'consideró', 'paìs', 'nuevo', 'cual', 'hemos', 'tuyos', 'manifestó', 'esto', 'haber', 'ha', 'durante', 'haya', 'tu', 'alguno', 'cuantas', 'sólo', 'estaban', 'están', 'mientras', 'donde', 'comentó', 'manera', 'eras', 'asi', 'haciendo', 'estan', 'ésta', 'saber', 'si', 'largo', 'total', 'vuestro', 'seis', 'empleais', 'dentro', 'fuera', 'cuál', 'encuentra', 'cuenta', 'mias', 'trabaja', 'cuántos', 'tras', 'tuya', 'nosotras', 'quien', 'buen', 'ella', 'verdadera', 'días', 'repente', 'podeis', 'aproximadamente', 'eso', 'trabajais', 'usamos', 'estas', 'habían', 'detras', 'lleva', 'tenemos', 'estos', 'les', 'expresó', 'empleo', 'cómo', 'solo', 'entre', 'primeros', 'vuestras', 'cuatro', 'cuando', 'propia', 'hoy', 'ellas', 'una', 'hacemos', 'apenas', 'ningunas', 'intentar', 'aquél', 'otra', 'grandes', 'tendrán', 'vez', 'esa', 'puede', 'siete', 'encima', 'ésa', 'podrá', 'próximos', 'quizá', 'quién', 'próximo', 'soyos', 'después', 'hay', 'sean', 'voy', 'mis', 'ellos', 'aunque', 'éstos', 'ésos', 'parte', 'anterior', 'será', 'alli', 'nuestros', 'posible', 'diferentes', 'dias', 'cosas', 'también', 'mía', 'menos', 'bueno', 'existen', 'usas', 'quiza', 'tener', 'través', 'había', 'arribaabajo', 'estuvo', 'podria', 'propias', 'ciertas', 'tenido', 'dejó', 'otras', 'tuyas', 'consiguen', 'haces', 'mia', 'nuevos', 'poco', 'las', 'esta', 'todo', 'tenga', 'tres', 'trata', 'atras', 'algunos', 'vais', 'valor', 'hizo', 'segun', 'mejor', 'mediante', 'segundo', 'verdad', 'dieron', 'solas', 'estais', 'mas', 'mismo', 'sí', 'van', 'mucho', 'gran', 'pasado', 'pesar', 'estará', 'no', 'os', 'junto', 'éste', 'muchos', 'emplean', 'luego', 'muy', 'trabajar', 'emplear', 'otros', 'cuáles', 'estaba', 'ampleamos', 'diferente', 'ocho', 'todavia', 'cuántas', 'veces', 'todas', 'acuerdo', 'hubo', 'empleas', 'ayer', 'hablan', 'breve', 'cerca', 'sería', 'porque', 'sino', 'intentais', 'está', 'fueron', 'aquí', 'ni', 'ningún', 'entonces', 'sabeis', 'actualmente', 'enfrente', 'muchas', 'hicieron', 'siempre', 'sabe', 'por', 'menudo', 'arriba', 'embargo', 'tus', 'tiempo', 'decir', 'trabajas', 'lejos']\n"
     ]
    }
   ],
   "source": [
    "stopwords = spacy.lang.es.stop_words.STOP_WORDS\n",
    "print('Número de stop words: ' + str(len(stopwords)))\n",
    "print('Stop words: ' + str(list(stopwords)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Los objetos de la clase ***Token*** tienen la propiedad ***is_stop*** que devuelve en Boolean indicando si el token es o no una stop word; es decir, si el ***Token*** (o palabra) esta dentro de la lista antes mostrada.\n",
    "* Veamos a continuación como obtener las stop words de una frase con spaCy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "por\n",
      "demasiado\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Un radar multa a Mariano. Rajoy por caminar demasiado rápido\")\n",
    "for word in doc:\n",
    "    if word.is_stop:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -Part of Speech (PoS)\n",
    "\n",
    "* En ***spaCy*** el PoS lo divide en 3 tipos de tags que son:\n",
    "    1. **pos**: etiqueta simple de alto nivel (verbo, nombre, adjetivo, etc).\n",
    "    2. **tag**: etiqueta con más nivel de detalle que el pos.\n",
    "    3. **dep**: dependencia sintáctica para ver la relación entre tokens.\n",
    "\n",
    "\n",
    "* Estos 3 tipos son propiedades de la clase ***Token***:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>PoS</th>\n",
       "      <th>TAG</th>\n",
       "      <th>DEP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Un</td>\n",
       "      <td>DET</td>\n",
       "      <td>DET__Definite=Ind|Gender=Masc|Number=Sing|Pron...</td>\n",
       "      <td>det</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>radar</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN__Gender=Masc|Number=Sing</td>\n",
       "      <td>nsubj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>multa</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VERB__Mood=Ind|Number=Sing|Person=3|Tense=Pres...</td>\n",
       "      <td>ROOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP__AdpType=Prep</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mariano</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN___</td>\n",
       "      <td>obj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rajoy</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN___</td>\n",
       "      <td>flat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>con</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP__AdpType=Prep</td>\n",
       "      <td>case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>300</td>\n",
       "      <td>NUM</td>\n",
       "      <td>NUM__NumForm=Digit</td>\n",
       "      <td>nummod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>€</td>\n",
       "      <td>NUM</td>\n",
       "      <td>NUM__NumForm=Digit|NumType=Card</td>\n",
       "      <td>obl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>por</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP__AdpType=Prep</td>\n",
       "      <td>mark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>caminar</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VERB__VerbForm=Inf</td>\n",
       "      <td>advcl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>demasiado</td>\n",
       "      <td>ADV</td>\n",
       "      <td>ADV___</td>\n",
       "      <td>advmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rápido</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ__Gender=Masc|Number=Sing</td>\n",
       "      <td>obj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Text    PoS                                                TAG  \\\n",
       "0          Un    DET  DET__Definite=Ind|Gender=Masc|Number=Sing|Pron...   \n",
       "1       radar   NOUN                      NOUN__Gender=Masc|Number=Sing   \n",
       "2       multa   VERB  VERB__Mood=Ind|Number=Sing|Person=3|Tense=Pres...   \n",
       "3           a    ADP                                  ADP__AdpType=Prep   \n",
       "4     Mariano  PROPN                                           PROPN___   \n",
       "5       Rajoy  PROPN                                           PROPN___   \n",
       "6         con    ADP                                  ADP__AdpType=Prep   \n",
       "7         300    NUM                                 NUM__NumForm=Digit   \n",
       "8           €    NUM                    NUM__NumForm=Digit|NumType=Card   \n",
       "9         por    ADP                                  ADP__AdpType=Prep   \n",
       "10    caminar   VERB                                 VERB__VerbForm=Inf   \n",
       "11  demasiado    ADV                                             ADV___   \n",
       "12     rápido    ADJ                       ADJ__Gender=Masc|Number=Sing   \n",
       "\n",
       "       DEP  \n",
       "0      det  \n",
       "1    nsubj  \n",
       "2     ROOT  \n",
       "3     case  \n",
       "4      obj  \n",
       "5     flat  \n",
       "6     case  \n",
       "7   nummod  \n",
       "8      obl  \n",
       "9     mark  \n",
       "10   advcl  \n",
       "11  advmod  \n",
       "12     obj  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"Un radar multa a Mariano Rajoy con 300€ por caminar demasiado rápido\")\n",
    "pos = [[tk.text, tk.pos_, tk.tag_, tk.dep_] for tk in doc]\n",
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame(pos, columns=[\"Text\", \"PoS\", \"TAG\", \"DEP\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -Named Entity Recognition (NER)\n",
    "\n",
    "* Named Entity Recognition (Reconocimiento de Entidades Nombradas) es una tarea de extracción de información que busca localizar y clasificar en categorías predefinidas, como personas, organizaciones, lugares, expresiones de tiempo y cantidades, las entidades nombradas encontradas en un texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leo Messi - PER - Named person or family.\n",
      "FC Barcelona - ORG - Companies, agencies, institutions, etc.\n",
      "La Liga - ORG - Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Leo Messi jugador del FC Barcelona marco 34 en La Liga 2017-18\")\n",
    "for entity in doc.ents:  \n",
    "    print(entity.text + ' - ' + entity.label_ + ' - ' + str(spacy.explain(entity.label_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "# -Resumen\n",
    "\n",
    "* Una vez creado el documento a partir del texto plano, tenemos ese texto tokenizado.\n",
    "* Los objetos de la clase ***Token*** tienen una serie de propiedades que permiten obtener mucha información relativa a los tokens (o palabras).\n",
    "* Haciendo un resumen de lo visto anteriormente podemos obtener la siguiente información de las palabras de un texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Lema</th>\n",
       "      <th>PoS</th>\n",
       "      <th>TAG</th>\n",
       "      <th>DEP</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>is Stop word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Un</td>\n",
       "      <td>Un</td>\n",
       "      <td>DET</td>\n",
       "      <td>DET__Definite=Ind|Gender=Masc|Number=Sing|Pron...</td>\n",
       "      <td>det</td>\n",
       "      <td>Xx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>radar</td>\n",
       "      <td>radar</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NOUN__Gender=Masc|Number=Sing</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>multa</td>\n",
       "      <td>multar</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VERB__Mood=Ind|Number=Sing|Person=3|Tense=Pres...</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP__AdpType=Prep</td>\n",
       "      <td>case</td>\n",
       "      <td>x</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mariano</td>\n",
       "      <td>Mariano</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN___</td>\n",
       "      <td>obj</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rajoy</td>\n",
       "      <td>Rajoy</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN___</td>\n",
       "      <td>flat</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>con</td>\n",
       "      <td>con</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP__AdpType=Prep</td>\n",
       "      <td>case</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>NUM</td>\n",
       "      <td>NUM__NumForm=Digit</td>\n",
       "      <td>nummod</td>\n",
       "      <td>ddd</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>€</td>\n",
       "      <td>€</td>\n",
       "      <td>NUM</td>\n",
       "      <td>NUM__NumForm=Digit|NumType=Card</td>\n",
       "      <td>obl</td>\n",
       "      <td>€</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>por</td>\n",
       "      <td>por</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP__AdpType=Prep</td>\n",
       "      <td>mark</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>caminar</td>\n",
       "      <td>caminar</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VERB__VerbForm=Inf</td>\n",
       "      <td>advcl</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>demasiado</td>\n",
       "      <td>demasiar</td>\n",
       "      <td>ADV</td>\n",
       "      <td>ADV___</td>\n",
       "      <td>advmod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rápido</td>\n",
       "      <td>rápido</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>ADJ__Gender=Masc|Number=Sing</td>\n",
       "      <td>obj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Text      Lema    PoS  \\\n",
       "0          Un        Un    DET   \n",
       "1       radar     radar   NOUN   \n",
       "2       multa    multar   VERB   \n",
       "3           a         a    ADP   \n",
       "4     Mariano   Mariano  PROPN   \n",
       "5       Rajoy     Rajoy  PROPN   \n",
       "6         con       con    ADP   \n",
       "7         300       300    NUM   \n",
       "8           €         €    NUM   \n",
       "9         por       por    ADP   \n",
       "10    caminar   caminar   VERB   \n",
       "11  demasiado  demasiar    ADV   \n",
       "12     rápido    rápido    ADJ   \n",
       "\n",
       "                                                  TAG     DEP  Shape  Alpha  \\\n",
       "0   DET__Definite=Ind|Gender=Masc|Number=Sing|Pron...     det     Xx   True   \n",
       "1                       NOUN__Gender=Masc|Number=Sing   nsubj   xxxx   True   \n",
       "2   VERB__Mood=Ind|Number=Sing|Person=3|Tense=Pres...    ROOT   xxxx   True   \n",
       "3                                   ADP__AdpType=Prep    case      x   True   \n",
       "4                                            PROPN___     obj  Xxxxx   True   \n",
       "5                                            PROPN___    flat  Xxxxx   True   \n",
       "6                                   ADP__AdpType=Prep    case    xxx   True   \n",
       "7                                  NUM__NumForm=Digit  nummod    ddd  False   \n",
       "8                     NUM__NumForm=Digit|NumType=Card     obl      €  False   \n",
       "9                                   ADP__AdpType=Prep    mark    xxx   True   \n",
       "10                                 VERB__VerbForm=Inf   advcl   xxxx   True   \n",
       "11                                             ADV___  advmod   xxxx   True   \n",
       "12                       ADJ__Gender=Masc|Number=Sing     obj   xxxx   True   \n",
       "\n",
       "    is Stop word  \n",
       "0          False  \n",
       "1          False  \n",
       "2          False  \n",
       "3          False  \n",
       "4          False  \n",
       "5          False  \n",
       "6           True  \n",
       "7          False  \n",
       "8          False  \n",
       "9           True  \n",
       "10         False  \n",
       "11          True  \n",
       "12         False  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "doc = nlp(\"Un radar multa a Mariano Rajoy con 300€ por caminar demasiado rápido\")\n",
    "\n",
    "result = [[tk.text, tk.lemma_, tk.pos_, tk.tag_, tk.dep_, tk.shape_, tk.is_alpha, tk.is_stop] for tk in doc]\n",
    "pd.DataFrame(result, columns=[\"Text\", \"Lema\", \"PoS\", \"TAG\", \"DEP\", \"Shape\", \"Alpha\", \"is Stop word\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para más información visitar el siguiente enlace: https://spacy.io/usage/spacy-101#annotations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
