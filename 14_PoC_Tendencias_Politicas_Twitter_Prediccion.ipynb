{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14 - Prueba de Concepto: Tendencias Pol√≠ticas en Twitter - Explotaci√≥n -\n",
    "\n",
    "\n",
    "* Este notebook es la continuaci√≥n del notebook: *13_PoC_Tendencias_Politicas_Twitter_Generacion_Exportacion_Modelos.ipynb*\n",
    "\n",
    "\n",
    "* En este notebook vamos a ***explotar*** un modelo ya creado anteriormente y va a tener como objetivo ***clasificar los tweets de una determinada cuenta de twitter*** en funci√≥n de su tendencia pol√≠tica.\n",
    "\n",
    "\n",
    "* Para realizar todo esto, lo haremos de la siguiente manera:\n",
    "\n",
    "    1. Lectura (via API) de los tweets de una determinada cuenta de twitter\n",
    "    2. Normalizaci√≥n de los tweets\n",
    "    3. Importaci√≥n de los modelos (Clasificaci√≥n y BoW)\n",
    "    3. Creacci√≥n de la Bolsa de Palabras (BoW) de los nuevos tweets\n",
    "    4. Predicci√≥n\n",
    "    \n",
    "    \n",
    "<hr>\n",
    "\n",
    "\n",
    "## Lectura (via API) de tweets\n",
    "\n",
    "* Para leer los tweets de una cuenta de twitter podemos usar el API de Twitter directamente o utilizar la librer√≠a ***tweepy*** que nos facilitamo mucho la labor a la hora de obtener datos de Twitter.\n",
    "\n",
    "\n",
    "* No tenemos como objetivo en este notebook explicar como funciona esta librer√≠a. Para saber de su funcionamiento podeis ver su p√°gina web: https://www.tweepy.org/\n",
    "\n",
    "\n",
    "* En esta punto vamos a leer 'N' tweets (si Twitter nos los facilita) de una determinada cuenta de Twitter.\n",
    "\n",
    "\n",
    "* En primer lugar tenemos que autenticarnos en Twitter con el protocolo OAuth (https://es.wikipedia.org/wiki/OAuth) y para ello necesitamos unos keys y unos tokens que nos proporcionar√° Twitter al registrar una APP. Este proceso de registro de una App es un poco tediodo y tampoco es el objetivo en esta PoC el explicar ese proceso. Para m√°s informaci√≥n visitar la web de desarrolladores de Twitter (https://developer.twitter.com/).\n",
    "\n",
    "\n",
    "* Nos autenticamos con Twitter:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "# Claves de cliente y tokens de acceso\n",
    "CONSUMER_KEY = 'fcCFQpt3lhMzeCgGhznWsb8C5'\n",
    "CONSUMER_SECRET = 'lljbTkudnEvn0SWn6ZPw5Svam6TzD9q58AhBsgrsqGN9AdqrvF'\n",
    "ACCESS_TOKEN = '1021745678974902279-7VhCtZkPsqhcaHPq4NFalaShazGbTV'\n",
    "ACCESS_TOKEN_SECRET = '0xDVjwimkp1WKjjZpMpLuj0V3aRkAeKuvc4DiHkyfvYkZ'\n",
    "\n",
    "# Proceso de autenticaci√≥n OAuth\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Vamos a petir a Twitter que nos devuelva de una determinada cuenta (*account*) un determinado n√∫mero de tweets (*num_tweets*)\n",
    "\n",
    "\n",
    "* Dado que se ha registrado una aplicaci√≥n de Twitter gratuita, es posible que Twitter no nos devuelva de una determinada cuenta todos los tweets que le pedimos.\n",
    "\n",
    "\n",
    "* A modo de poder probar esta prueba de concepto, dejo algunas cuentas de Twitter (de marcado caracter pol√≠tico) para predecir cual es su tendencia pol√≠tica. Esta cuentas no han sido utilizadas para generar el dataset con el que hemos generado el modelo.\n",
    "\n",
    "    - I√±igo Errejon: @ierrejon\n",
    "    - Manuela Carmena: @ManuelaCarmena\n",
    "    - Susana D√≠az: @susanadiaz\n",
    "    - Josep Borrell: @JosepBorrellF\n",
    "    - Mariano Rajoy: @marianorajoy\n",
    "    - Jordi Evole: @jordievole\n",
    "    - Eduardo Inda: @eduardoinda\n",
    "    - Jorge Verstrynge: @VerstryngeJorge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 - @DavidJarR Tal cual\n",
      "\n",
      "1 - @carla_varona @Panchovarona @ObjetivoLaSexta @_anapastor_ ‚ò∫Ô∏è\n",
      "\n",
      "2 - @Panchovarona @ObjetivoLaSexta @_anapastor_ Gracias Pancho!!!\n",
      "\n",
      "3 - @YaizaYgarcia Gracias a ti por decirlo!\n",
      "\n",
      "4 - @MiguelAML2 Muchas gracias , Miguel !\n",
      "\n",
      "5 - @NisaAlberto Gracias!!\n",
      "\n",
      "6 - Apostar por energ√≠as verdes es reducir la factura de la luz. https://t.co/4MvnxEWX8A\n",
      "\n",
      "7 - @tardedetortasf2 A ti! üòä\n",
      "\n",
      "8 - Para que la crisis no la paguen los de siempre: https://t.co/bEs05d5EXX\n",
      "\n",
      "9 - @tiguel_mena @Caquel__ @gabrielrufian ¬øEn esta, dices? https://t.co/vE4EAP5jad\n",
      "\n",
      "10 - El elefante en el hemiciclo. https://t.co/IzZwMdOhHV\n",
      "\n",
      "11 - @Alexa4u2 üòä‚úåüèº\n",
      "\n",
      "12 - @CuetoMartos Las comas, por favor.\n",
      "\n",
      "13 - @RTalaveraM2 Gracias!!\n",
      "\n",
      "14 - Todo el d√≠a con ‚ÄúEspa√±a‚Äù en la boca y a la hora de la verdad van con las el√©ctricas y las petroleras antes que con su pa√≠s. https://t.co/kN5Uql25bp\n",
      "\n",
      "15 - @Juanmahuerta Pues tienes toda la raz√≥n . Gracias por decirlo .\n",
      "\n",
      "16 - El mercado: hecha la ley, hecha la trampa https://t.co/qygQEVNu15\n",
      "\n",
      "17 - @aibeltranmoreno @htejero_ En mi biblioteca reina la m√°s alta expresi√≥n del orden (NO).\n",
      "\n",
      "18 - @aibeltranmoreno @htejero_ Qui√©n dice eso?\n",
      "\n",
      "19 - @HugodePayns6 Seguro que ya sabes que es un puesto no remunerado y que el organismo es solo consultivo y cualquier decisi√≥n le pertenece al gobierno de la comunidad de Madrid. Y , si no, seguro que tras saberlo te disculpas.\n",
      "\n",
      "20 - Lo dijimos, Putin es de los suyos: https://t.co/h6qpIUhOG3\n",
      "\n",
      "21 - Menos ir al palco de Vallekas a provocar y m√°s ponerse del lado de las reivindicaciones del rayismo. https://t.co/9nFR6uy3WS\n",
      "\n",
      "22 - En Espa√±a hay m√°s de medio mill√≥n de trabajadoras del hogar. Desde @MasMadridCM y @MasPais_Es instamos al Gobierno a reconocerles sus derechos y garantizarles la prestaci√≥n por desempleo. https://t.co/8Tyc6Qh4JX\n",
      "\n",
      "23 - Una transici√≥n energ√©tica que cambie el modelo. Impulsar el autoconsumo y las comunidades energ√©ticas para acabar con el oligopolio, democratizar el sistema y abaratar la energ√≠a. https://t.co/mpCvDtlokA\n",
      "\n",
      "24 - @bobiskiu N√≥tese el condicional ‚Äúsi‚Äù . Un saludo!\n",
      "\n",
      "25 - @cordoba_fali https://t.co/8Lljyqlnya\n",
      "\n",
      "Supongo que te disculpar√°s.\n",
      "\n",
      "26 - @FedericoRG üòâ\n",
      "\n",
      "27 - El Gobierno ha reaccionado r√°pido, queda por ver si ha reaccionado bien. Si el paquete de medidas es verde y es justo, contar√° con nuestro apoyo. https://t.co/m32PEjQA3E\n",
      "\n",
      "28 - @vidalmatas14 @cordaipoalcoop @CarmeGomila @MESperMallorca ‚úäüèºüòä\n",
      "\n",
      "29 - Moltes gr√†cies @cordaipoalcoop per acollir-nos i ser llar de comunitat. Moltes gr√†cies @vidalmatas14 i @carmegomila pels comentaris i companyia. Una abra√ßada a tota la gent de @MESperMallorca, referents i companys d' un mateix cam√≠.\n",
      "\n",
      "30 - Hi ha presentacions del llibre que esdevenen converses animades, amb complicitat i deliberaci√≥ que ens fan a tots anar m√©s enll√† de les nostres posicions de partida. Com la d‚Äô avui a Mallorca. Tot un luxe. https://t.co/h3gnTwmpCi\n",
      "\n",
      "31 - @pepcalabona Fins a la propera, company! No trigarem gaire‚Ä¶\n",
      "\n",
      "32 - @ladypalo üôàüôà\n",
      "\n",
      "33 - @dardermascaro @CarmeGomila @vidalmatas14 @antonitrobat Ha estat un plaer. Salut!\n",
      "\n",
      "34 - @Kamchatka_H Venga que ya est√°s!! Un besazo\n",
      "\n",
      "35 - @CarmeGomila Amb moltes ganes de xerrar dem√†!\n",
      "\n",
      "36 - @jommna @CarmeGomila @vidalmatas14 https://t.co/8Lljyqlnya\n",
      "\n",
      "Estoy convencido de que te vas a disculpar por difundir mentiras.\n"
     ]
    }
   ],
   "source": [
    "account = '@ierrejon'\n",
    "num_tweets = 50\n",
    "tweets = list()\n",
    "for user_status in api.user_timeline(screen_name=account, count = num_tweets, include_rts=False, tweet_mode=\"extended\"):\n",
    "        tweets.append(user_status.full_text)\n",
    "\n",
    "for index, tweet in enumerate(tweets):\n",
    "    print('\\n{} - {}'.format(index, tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "## Normalizaci√≥n\n",
    "\n",
    "\n",
    "* Tenemos que normalizar de la misma manera que se han normlizado los tweets con los que se generaron el modelo.\n",
    "\n",
    "\n",
    "* Realizamos las misma acciones para ***normalizar*** los tweets:\n",
    "    1. Pasamos las frases a min√∫sculas.\n",
    "    2. Sustituimos los puntos por espacios ya que hay muchas palabras unidas por un punto\n",
    "    3. Quitamos la almuhadilla de los hashtags para considerarlos como palabras.\n",
    "    4. Eliminamos los signos de puntuaci√≥n.\n",
    "    5. Eliminamos las palabras con menos de 3 caracteres.\n",
    "    6. Eliminamos las Stop-Words.\n",
    "    7. Eliminamos los enlaces(http) y las menciones (@)\n",
    "    8. Pasamos la palabra a su lema\n",
    "    \n",
    "\n",
    "* Por √∫ltimo vamos a eliminar los tweets que tras la normalizaci√≥n no contengan ninguna palabra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 37/37 [00:00<00:00, 179.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N¬∫ de Tweets validos de @ierrejon: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "def normalize(tweets, min_words=3):\n",
    "    \"\"\"\n",
    "    Funci√≥n que dada una lista de tweets ([tweet, clase]), normaliza los tweets y devuelve una lista\n",
    "    con los tweets normalizados, descartando aquellos tweets que tras la normalizaci√≥n tengan menos de\n",
    "    \"min_words\" palabras en el tweet.\n",
    "    \n",
    "    :param tweets:       Lista de Tweets ([tweet, clase]) con el tweet y la clase a la que pertenece\n",
    "    :param min_words:    N√∫mero minimo de palabras que tiene que tener un tweet tras la normalizaci√≥n\n",
    "    :return:             Lista de Tweets ([tweet, clase]) normalizados\n",
    "    \"\"\"\n",
    "    tweets_list = []\n",
    "    for tweet in tqdm(tweets):\n",
    "        # Tokenizamos el tweets realizando los puntos 1,2 y 3.\n",
    "        tw = nlp(tweet.lower().replace('.', ' ').replace('#', ' ').strip())\n",
    "        \n",
    "        # Normalizamos Puntos 4,5,6,7 y 8\n",
    "        tw = ([word.lemma_ for word in tw if (not word.is_punct)\n",
    "               and (len(word.text) > 2) and (not word.is_stop)\n",
    "               and (not word.text.startswith('@'))\n",
    "               and (not word.text.startswith('http'))\n",
    "               and (not ':' in word.text)])\n",
    "        \n",
    "        # Eliminamos los tweets que tras la normalizaci√≥n tengan menos de \"min_words\" palabras\n",
    "        if len(tw) >= min_words:\n",
    "            tweets_list.append(\" \".join(tw))\n",
    "    return tweets_list\n",
    "\n",
    "# Normalizamos las frases\n",
    "X_norm = normalize(tweets, min_words=5)\n",
    "\n",
    "print('N¬∫ de Tweets validos de {}: {}'.format(account, len(X_norm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "## Importamos los modelos\n",
    "\n",
    "* Vamos a importar los modelos creados en el notebook *13_PoC_Tendencias_Politicas_Twitter_Generacion_Exportacion_Modelos.ipynb*\n",
    "\n",
    "\n",
    "* Temos que importar:\n",
    "    1. El modelo creado con el Algoritmo de Aprendizaje ***Bernoulli Naive Bayes***\n",
    "    2. El modelo para crear la Bolsa de Palabras\n",
    "    \n",
    "    \n",
    "#### 1. Importamos el modelo para la clasificaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = './models/13_best_model_tweets_politica.pickle'\n",
    "classifier_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Importamos el modelo para crear la Bolsa de Palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './models/13_vectorizer_bow_tweets_politica.pickle'\n",
    "vectorizer = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "## Creamos la Bolsa de Palabras\n",
    "\n",
    "\n",
    "* Tenemos que usar el modelo de bolsa de palabras creado con los tweets de entrenamiento ya que contiene el diccionario (o vocabulario) con el que se ha entrenado el modelo para la clasificaci√≥n.\n",
    "\n",
    "\n",
    "* Este diccionario contiene 1000 palabras y los tweets que tenemos que predecir hay que transformalos a un vector de frecuencias donde nos diga cuantas veces aparecen las palabras del tweets dentro de esas 1000 palabras con las que hemos entrenado.\n",
    "\n",
    "\n",
    "* En el caso de que un tweet contenga una palabra que no est√© entre esas 1000 palabras, esta palabra no se tendr√° en cuenta para predecir la tendencia pol√≠tica del tweet, ya que el modelo no ha sido entrenado con esa palabra.\n",
    "\n",
    "\n",
    "* Vamos a pasar ***Bolsa de Palabras de frecuencias*** los tweets leidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bow = vectorizer.transform(X_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "## Predicci√≥n\n",
    "\n",
    "\n",
    "* Con el modelo importado y la bolsa de palabras creada, vamos a clasificar cada unos de los tweets en su tendencia pol√≠tica.\n",
    "\n",
    "\n",
    "* Para ello vamos a llamar al m√©todo \"***predict()***\" y le vamos a pasar la ***Bolsa de palabras de los Tweets*** para que nos clasifique ese tweet.\n",
    "\n",
    "\n",
    "* Como lo que nos interesa es ***clasificar la cuenta de Twitter*** (o persona que esta detras de esa cuenta) en su ***tendencia pol√≠tica***, vamos a calcular los porcentajes de clasificaci√≥n de los tweets en su tendencia pol√≠tica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "podemos = 35.7%\n",
      "vox = 28.6%\n",
      "pp = 7.1%\n",
      "psoe = 28.6%\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier_model.predict(X_bow)\n",
    "prediccion = dict()\n",
    "total = 0\n",
    "for pred in predictions:\n",
    "    if pred in prediccion:\n",
    "        prediccion[pred] += 1\n",
    "    else:\n",
    "        prediccion[pred] = 1\n",
    "    total += 1\n",
    "        \n",
    "for k,v in prediccion.items():\n",
    "    print('{partido} = {porc:0.1f}%'.format(partido=k, porc=(v/float(total))*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
