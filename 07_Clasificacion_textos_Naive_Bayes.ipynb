{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07 - Clasificación de textos con Naive Bayes: Introducción\n",
    "\n",
    "* Uno de los temas interesantes del ***Procesamiento del Lenguaje Natural*** es el de la clasificación de textos.\n",
    "\n",
    "\n",
    "* Los problemas de clasificación se encuentran dentro del ***aprendizaje supervisado***, lo que significa que para la clasificación de texto previamente se tiene que disponer de una serie de texto etiquetados (o clasificados).\n",
    "\n",
    "\n",
    "* Por tanto para la clasificación de textos se necesita un ***array de características del texto*** (Bolsa de Palabras) y una ***etiqueta asociada*** a ese texto.\n",
    "\n",
    "\n",
    "* Uno de los clasificadores más sencillos de entender es el clasificador ***Naive Bayes***, que es un clasificador probabilístico que se basa en el ***teorema de Bayes***\n",
    "\n",
    "<hr>\n",
    "\n",
    "* Veamos a continuación como clasificar textos utilizando un clasificador ***Naive Bayes***:\n",
    "\n",
    "### 1.- Probabilidad de que una palabra pertenezca a una etiqueta:\n",
    "\n",
    "* Definimos la probabilidad de que una **palabra** pertenezca a una **etiqueta** de la siguiente manera:\n",
    "\n",
    "\n",
    "$$P(etiqueta|palabra) = \\frac{P(etiqueta) \\cdot P(palabra|etiqueta)}{P(palabra)}$$\n",
    "\n",
    "* Veamos paso por paso como calcular la probabilidad que dada una palabra, esta pertenezca a una etiqueta:\n",
    "\n",
    "    1. **Probabilidad de la Palabra** - *P(palabra)*:\n",
    "<br>       \n",
    "       $$P(palabra) = \\frac{Nº \\: apariciones \\: palabra}{Nº \\: palabras \\: totales \\: corpus}$$\n",
    "<br>\n",
    "    2. **Probabilidad de la Etiqueta** - *P(etiqueta)*:\n",
    "<br>   \n",
    "       $$P(etiqueta) = \\frac{Nº \\: apariciones \\: de \\: palabras \\: con \\: esa \\: etiqueta}{Nº \\: palabras \\: totales \\: corpus}$$\n",
    "<br>       \n",
    "    3. **Probabilidad de que una etiqueta pertenezca a una palabra** - *P(palabra|etiqueta)*:\n",
    "<br>   \n",
    "       $$P(palabra|etiqueta) = \\frac{Nº \\: veces \\: que \\: aparece \\: la \\: palabra \\: con \\: esa \\: etiqueta}{Nº \\: apariciones \\: de \\: palabras \\: con \\: esa \\: etiqueta}$$\n",
    "<br> \n",
    "\n",
    "### 2.- Probabilidad de que un texto pertenezca a una etiqueta:\n",
    "\n",
    "* El clasificador ***Naive Bayes*** elige en primer lugar la ***etiqueta más probable*** para un texto, asumiendo que los textos los clasificamos \"de primeras\" sin tener información sobre el contenido del texto.\n",
    "\n",
    "\n",
    "* En segundo lugar mira las características individuales del texto (las palabras) asumiendo que todas las características son independientes entre sí. Esta suposición es la que hace \"ingenuo\" (Naive en ingles) al clasificador de Bayes ya que las características (las palabras) no son independientes entre sí.\n",
    "\n",
    "\n",
    "* Por tanto se define la probabilidad de que un documento pertenezca a una etiqueta como el producto de la probabilidad de la etiqueta junto al productos de las probabilidades particulares de cada palabra:\n",
    "\n",
    "\n",
    "$$P(etiqueta_j|documento) = P(etiqueta_j)  \\cdot \\prod_{etiqueta_j\\in Etiquetas} P(palabra_i | etiqueta_j)$$\n",
    "\n",
    "<hr>\n",
    "\n",
    "## Ejemplo:\n",
    "\n",
    "* Veamos a continuación como clasificar textos utilizando un clasificador ***Naive Bayes***, suponiendo que tenemos 5 textos clasificados cada unos de ellos por la temática \"Real Madrid\" o \"Barça\". Los textos serian los siguientes:\n",
    "\n",
    "    - **T1 (Real Madrid)**: Ronaldo Ronaldo Ronaldo Ronaldo Futbol\n",
    "    - **T2 (Real Madrid)**: Ronaldo Ramos Ramos Messi\n",
    "    - **T3 (Real Madrid)**: Ramos Ramos Ramos Ronaldo Messi Iniesta Futbol\n",
    "    - **T4 (Barça)**: Messi Messi Messi Iniesta Futbol Ronaldo\n",
    "    - **T5 (Barça)**: Messi Messi Iniesta Iniesta Iniesta Ramos Futbol\n",
    "    \n",
    "    \n",
    "#### Datos:\n",
    "\n",
    "* ***Documentos***:\n",
    "    - Número total de documentos = 5\n",
    "    - Número de documentos etiquetados como \"Real Madrid\" = 3\n",
    "    - Número de documentos etiquetados como \"Barça\" = 2\n",
    "    - P(Real Madrid) = 3/5\n",
    "    - P(Barça) = 2/5\n",
    "    \n",
    "\n",
    "* ***Palabras***:\n",
    "    - Número total de palabras = 29\n",
    "    - Número total de palabras etiquetadas como Real Madrid = 16\n",
    "    - Número total de palabras etiquetadas como Barça = 13\n",
    "    \n",
    "|Palabra|Apariciones|Apariciones(Real Madrid)|Apariciones(Barça)|P(palabra)|P(palabra/Real Madrid)|P(palabra/Barça)|\n",
    "|---|---|---|---|---|---|---|\n",
    "|Ronaldo|7|6|1|7/29|6/16|1/13|\n",
    "|Ramos|6|5|1|6/29|5/16|1/13|\n",
    "|Messi|7|2|5|7/29|2/16|5/13|\n",
    "|Iniesta|5|1|4|5/29|1/16|4/13|\n",
    "|Futbol|4|2|2|4/29|2/16|2/13|\n",
    "\n",
    "#### Clasificación:\n",
    "* Supongamos que tenemos el siguiente texto a clasificar:\n",
    "    - **$Doc_{new}$**: Ronaldo Ronaldo Messi Futbol\n",
    "    \n",
    "    \n",
    "* ***Clasificación del texto Tt1***:\n",
    "\n",
    "$$P(Real Madrid|Doc_{new}) = P(Real Madrid) \\cdot P(Ronaldo|Real Madrid) \\cdot P(Ronaldo|Real Madrid) \\cdot P(Messi|Real Madrid) \\cdot P(Futbol|Real Madrid)$$ $$ = 3/5 \\cdot 6/16 \\cdot 6/16 \\cdot 2/16 \\cdot 2/16 = 1.32\\cdot10^{-3}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$P(Barça|Doc_{new}) = P(Barça) \\cdot P(Ronaldo|Barça) \\cdot P(Ronaldo|Barça) \\cdot P(Messi|Barça) \\cdot P(Fútbol|Barça)$$ $$= 2/5 \\cdot 1/13 \\cdot 1/13 \\cdot 5/13 \\cdot 2/13 = 1.4\\cdot10^{-4}$$\n",
    "\n",
    "* ***Resultado***: P(Real Madrid|$Doc_{new}$) = 1.32·10<sup>-3</sup> > P(Barça|$Doc_{new}$) = 1.4·10<sup>-4</sup> -> ***Clasificado como \"Real Madrid\"***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "textos = [('Ronaldo Ronaldo Ronaldo Ronaldo Futbol', 'Real Madrid'),\n",
    "          ('Ronaldo Ramos Ramos Messi', 'Real Madrid'),\n",
    "          ('Ramos Ramos Ramos Ronaldo Messi Iniesta Futbol', 'Real Madrid'),\n",
    "          ('Messi Messi Messi Iniesta Futbol Ronaldo', 'Barça'),\n",
    "          ('Messi Messi Iniesta Iniesta Iniesta Ramos Futbol', 'Barça')]\n",
    "\n",
    "\n",
    "def to_bow(textos, label='all'):\n",
    "    \"\"\"Función que dada una lista de textos etiquetados, devuelve una bolsa de palabras por frecuencia\"\"\"\n",
    "    bow = dict()\n",
    "    for text in textos:\n",
    "        if text[1] == label or label == 'all':\n",
    "            for word in text[0].split(' '):\n",
    "                if word in bow:\n",
    "                    bow[word] += 1\n",
    "                else:\n",
    "                    bow[word] = 1\n",
    "    return bow\n",
    "\n",
    "bow = to_bow(textos)\n",
    "bow_madrid = to_bow(textos, 'Real Madrid')\n",
    "bow_barsa = to_bow(textos, 'Barça')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ronaldo': 7, 'Futbol': 4, 'Ramos': 6, 'Messi': 7, 'Iniesta': 5}\n",
      "{'Ronaldo': 6, 'Futbol': 2, 'Ramos': 5, 'Messi': 2, 'Iniesta': 1}\n",
      "{'Messi': 5, 'Iniesta': 4, 'Futbol': 2, 'Ronaldo': 1, 'Ramos': 1}\n"
     ]
    }
   ],
   "source": [
    "print(bow)\n",
    "print(bow_madrid)\n",
    "print(bow_barsa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "# Bonus Track - Teorema de Bayes (Naive Bayes)\n",
    "\n",
    "\n",
    "## - Teorema de Bayes\n",
    "\n",
    "* Uno de los clasificadores más sencillos de entender es el clasificador ***Naive Bayes***, que es un clasificador probabilístico que se basa en el ***Teorema de Bayes***.\n",
    "\n",
    "\n",
    "* El ***Teorema de Bayes*** define lo siguiente:\n",
    "\n",
    "\n",
    "<span style=\"font-size:20px\">$$P(y|x) = \\frac{P(x|y) \\cdot P(y)}{P(x)}$$</span>\n",
    "\n",
    "\n",
    "* Con el ***Teorema de bayes podemos calcular la probabilidad $P(y|x)$***, que es la probabilidad de que un elemento 'x' pertenezca a una clase 'y', ***teniendo unicamente como datos***:\n",
    "<span></span><br><br>\n",
    "    + ***$P(x)$ - Probabilidad Marginal***: Probabilidad de los elementos 'x'.\n",
    "<span></span><br><br>\n",
    "    + ***$P(y)$ - Probabilidad a priori***: Probabilidad de las clases 'y'.\n",
    "<span></span><br><br>\n",
    "    + ***$P(x|y)$ - Probabilidad condicionada***: Probabilidad de los casos de cada clase.\n",
    "\n",
    "\n",
    "* Resumiendo, tenemos lo siguiente:\n",
    "\n",
    "\n",
    "<img src=\"./imgs/020_bayes.png\" style=\"width: 400px;\"/>\n",
    "\n",
    "\n",
    "## - Naive Bayes\n",
    "\n",
    "\n",
    "* Una simplificación del Teorema de Bayes es ***asumir que las variables mediante las que se describen nuestros elementos son independientes***.\n",
    "\n",
    "\n",
    "* Si añadimos esta suposición a nuestro clasificador tenemos lo que se conoce como ***Naive Bayes*** (el Bayes Ingenuo), por lo que ***podemos calcular la probabilidad a posteriori*** (o la probabilidad de que un elemento pertenezca a una clase) como:\n",
    "\n",
    "\n",
    "<span style=\"font-size:20px\">$$P(y=y_j|x) = P(x|y=y_j) \\cdot P(y_j)$$</span>\n",
    "\n",
    "\n",
    "* Aunque en el ejemplo anterior nuestro conjunto de datos solo tenia una variable, cada elemento de nuestro Dataset podrá tener 'n' variables, las cuales asumimos que son independientes; por tanto, calculamos la ***probabilidad condicionada*** como:\n",
    "\n",
    "\n",
    "$$P(x|y=y_j) = P(x_1|y=y_j) \\: \\times \\: ... \\: \\times \\: P(x_n|y=y_j) = \\prod_{i=1}^{n} P(x_i|y=y_j)$$\n",
    "\n",
    "\n",
    "* Por tanto ***calculamos la probabilidad a posteriori*** definida por el clasificador ***Naive Bayes*** como:\n",
    "\n",
    "<span style=\"font-size:20px\">$$P(y=y_j|x) = P(y=y_j) \\cdot \\prod_{i=1}^{n} P(x_i|y=y_j)$$</span>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
