{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6c8f822",
   "metadata": {},
   "source": [
    "# 24 - Explotación de Modelos Pre-Entrenados en Hugging Face - Transformers\n",
    "\n",
    "\n",
    "\n",
    "## ¿Qué es Hugging Face?\n",
    "\n",
    "\n",
    "* Hugging Face (https://huggingface.co/) es una web con una grandisima comunidad, que permite la los usuarios compartir y consumir modelos pre-entrenados (con técnicas de Deep Learning) dirigidos principalmente al campo del NLP.\n",
    "\n",
    "\n",
    "* Su principal modo de operación gira entorno al uso de transformers; un nuevo modelo de Deep Learning presentado por google en 2017.\n",
    "\n",
    "\n",
    "* También es utilizado para compartir datasets (corpus) entre otras cosas.\n",
    "\n",
    "\n",
    "* En la siguiente imagen podemos ver la forma que tiene la web para la selección de modelos:\n",
    "\n",
    "<img src=\"./imgs/036_Hugging_Face_WEB.png\"/>\n",
    "\n",
    "\n",
    "* En el siguiente enlace \"https://huggingface.co/course/chapter1/1\" esta disponible un curso introductorio de Hugging Face.\n",
    "\n",
    "\n",
    "\n",
    "## ¿Qué son los Transformers?\n",
    "\n",
    "\n",
    "* Los ***Transformers son modelos de deep learning***, diseñados para ***manejar datos secuenciales*** principalmente en el campo del procesamiento de lenguaje natural (NLP): traducción, clasificación, sumarización (resumenes) de textos, o bien en el campo de las series temporales como el forecasting o trading.\n",
    "\n",
    "\n",
    "* Los transformers fueron presentados en 2017 en el Paper ***'Attention Is All You Need'*** por el equipo de Google: https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\n",
    "\n",
    "<img src=\"./imgs/035_Transformers_Arquitectura.png\"/>\n",
    "\n",
    "<center><h5>Imagen obtenida del paper 'Attention Is All You Need'</h5></center>\n",
    "\n",
    "\n",
    "* ***La arquitectura de los Transformers*** contienen ***un sistema de encoding y decoding por capas***, acompañadas por un modelo de \"self-attention\".\n",
    "\n",
    "\n",
    "* A diferencia de las redes neuronales recurrentes (las mejores redes hasta ese momento para el NLP), los Transformers no requieren que los datos estén ordenados; es decir, que si el input del modelo es una oración (una secuencia de palabras), el Transformer no necesita partir desde la primera palabra hasta la última secuencialmente para ofrecer la predicción. Esto le permite a los Transformers una mayor paralelización que las redes neuronales recurrentes lo que se traduce en menores tiempos de entrenamiento.\n",
    "\n",
    "\n",
    "## ¿Cómo funcionan los transformers?\n",
    "\n",
    "\n",
    "1. El Transformer recibe una oración de entrada y la convierte en dos secuencias: \n",
    "\n",
    "    1.1. una **secuencia de vectores de palabras**: cada palabra del diccionario la representa como un vector\n",
    "    \n",
    "    1.2. una **secuencia de codificaciones posicionales**: representación vectorial de la posición de la palabra en la oración\n",
    "    \n",
    "\n",
    "2. El transformer junta ambas secuencias y pasa el resultado a través de una serie de codificadores, seguidos de una serie de decodificadores. Se puede observar en este punto como la oración de entrada se puede procesar toda a la vez y no de manera secuencial como se haría con las redes neuronales recurrentes.\n",
    "\n",
    "3. Cada uno de los codificadores convierte su entrada en otra secuencia de vectores llamados codificaciones.\n",
    "\n",
    "4. Los decodificadores hacen lo contrario; convertir las codificaciones en una secuencia de probabilidades de diferentes palabras de salida.\n",
    "\n",
    "5.  Cada codificador y decodificador contiene un componente llamado mecanismo de atención, que le permite generar un contexto a cada palabra que procesa\n",
    "\n",
    "6. Finalmente las probabilidades numéricas en la capa de salida se pueden convertir en otra oración en lenguaje natural usando la función softmax.\n",
    "\n",
    "\n",
    "* Enlace de interes para comprender el detalle de los Transformers: https://deepai.org/machine-learning-glossary-and-terms/transformer-neural-network\n",
    "\n",
    "\n",
    "## Modelos Pre-entrenados con Transformers:\n",
    "\n",
    "\n",
    "* Existen una serie de modelos pre-entrenados (principalmente en inglés) que tiene como objetivo servir como base para posteriormento resolver tareas concretas como la clasifiación de textos, traducción, resumenes de textos, etc.\n",
    "\n",
    "\n",
    "* Podemos decir que estos modelos que se muestran en la siguiente imagen (ELMo, Bert, GPT3, etc.) serian modelos que han aprendido la tarea de \"saber leer\" y que posteriormente son usados en los entrenamientos para resolver tareas más específicas como las antes mencionadas de clasifiación de textos, traducción, resumenes de textos, etc.\n",
    "\n",
    "<img src=\"./imgs/037_Modelos_Pre-Entrenados_NLP3.png\"/>\n",
    "\n",
    "<center><h5>Imagen obtenida de: https://spyro-soft.com/blog/tomasz-smolarczyk-the-future-of-ai</h5></center>\n",
    "\n",
    "\n",
    "* Existen modelos en Español como ***BETO, MarIA y BERTIN\":\n",
    "\n",
    "<img src=\"./imgs/038_Modelos_Pre-Entrenados_NLP_espaniol.png\"/>\n",
    "\n",
    "<center><h5>Imagen obtenida del video: 'Entrenando un modelo de lenguaje del español del estado del arte - Hackathon de PLN en Español': https://youtu.be/3OhArr1R2Lw</h5></center>\n",
    "\n",
    "\n",
    "* En el video 'Entrenando un modelo de lenguaje del español del estado del arte - Hackathon de PLN en Español' ( https://youtu.be/3OhArr1R2Lw) un equipo del Instituto de Ingeniería del Conocimiento muestra el proceso por el cual han construido el modelo ***RigoBERTa*** para posteriormente resolver diferentes tareas.\n",
    "\n",
    "\n",
    "## ¿Cómo explotamos los Modelos Pre-entrenados de Hugging Face?\n",
    "\n",
    "\n",
    "* A continuación vamos a ver cómo importar y explotar los modelos disponibles en Hugging Face, para resolver las tareas de:\n",
    "\n",
    "    1. [Clasificación](#M1)\n",
    "    2. [Traducción](#M2)\n",
    "    3. [Resumenes de Textos](#M3)\n",
    "    4. [NER (Reconocimiento de Entidades Nombradas)](#M4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8d6c8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95abe344",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "# <a name=\"M1\">1.- Clasificación</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3809ec3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998812675476074}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I love this car\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af13153b",
   "metadata": {},
   "source": [
    "* Podemos pasar una lista de frases para su predicción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "858863b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998812675476074},\n",
       " {'label': 'NEGATIVE', 'score': 0.994215190410614}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier([\"I love this car\",\n",
    "            \"I do not like this car\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37567fa9",
   "metadata": {},
   "source": [
    "* A continuación un ejemplo más completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63f5fd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: POSITIVE - Real: POSITIVE - ACIERTO: True - Score: 0.999884843826294 - Frase: I feel happy this morning\n",
      "Prediction: POSITIVE - Real: POSITIVE - ACIERTO: True - Score: 0.9995887875556946 - Frase: Larry is my friend\n",
      "Prediction: NEGATIVE - Real: NEGATIVE - ACIERTO: True - Score: 0.9950820207595825 - Frase: I do not like that man\n",
      "Prediction: NEGATIVE - Real: NEGATIVE - ACIERTO: True - Score: 0.9997738003730774 - Frase: My house is not great\n",
      "Prediction: NEGATIVE - Real: NEGATIVE - ACIERTO: True - Score: 0.9997772574424744 - Frase: Your song is annoying\n",
      "Prediction: POSITIVE - Real: POSITIVE - ACIERTO: True - Score: 0.9998492002487183 - Frase: The beer was good.\n",
      "Prediction: NEGATIVE - Real: NEGATIVE - ACIERTO: True - Score: 0.9997217059135437 - Frase: I do not enjoy my job\n",
      "Prediction: POSITIVE - Real: POSITIVE - ACIERTO: True - Score: 0.9998800754547119 - Frase: I feel amazing!\n",
      "Prediction: POSITIVE - Real: POSITIVE - ACIERTO: True - Score: 0.9997559189796448 - Frase: Gary is a friend of mine.\n",
      "Prediction: NEGATIVE - Real: NEGATIVE - ACIERTO: True - Score: 0.9641065001487732 - Frase: I can't believe I'm doing this.\n"
     ]
    }
   ],
   "source": [
    "test = [('I feel happy this morning', 'POSITIVE'),\n",
    "        ('Larry is my friend', 'POSITIVE'),\n",
    "        ('I do not like that man', 'NEGATIVE'),\n",
    "        ('My house is not great', 'NEGATIVE'),\n",
    "        ('Your song is annoying', 'NEGATIVE'),\n",
    "        ('The beer was good.', 'POSITIVE'),\n",
    "        ('I do not enjoy my job', 'NEGATIVE'),\n",
    "        (\"I feel amazing!\", 'POSITIVE'),\n",
    "        ('Gary is a friend of mine.', 'POSITIVE'),\n",
    "        (\"I can't believe I'm doing this.\", 'NEGATIVE')]\n",
    "\n",
    "# Obtenemos las predicciones\n",
    "pred = classifier([t[0] for t in test])\n",
    "\n",
    "# Imprimimos la predicción, la realidad, el score y la frase\n",
    "for index, prediction in enumerate(pred):\n",
    "    print(\"Prediction: {} - Real: {} - ACIERTO: {} - Score: {} - Frase: {}\"\n",
    "          .format(prediction['label'], \n",
    "                  test[index][1], \n",
    "                  prediction['label'] == test[index][1], \n",
    "                  prediction['score'], \n",
    "                  test[index][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a385f77d",
   "metadata": {},
   "source": [
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "## 1.1.- Selección y Explotación de modelos de clasificación ya entrenados (En Español)\n",
    "\n",
    "* Dentro de la web de Hugging Face (https://huggingface.co/) podemos visualizar y seleccionar mediante filtros, aquellos modelos ya entrenados que puedan satisfacer las necesidades de nuestro problema.\n",
    "\n",
    "\n",
    "* En el siguiente ejemplo vamos a ***seleccionar un modelo con las siguientes características***:\n",
    "\n",
    "    1.- Modelo para la ***clasificación de textos (Análisis de Sentimientos)***\n",
    "    \n",
    "    2.- Que sepa clasificar textos ***en Español***.\n",
    "    \n",
    "\n",
    "* Para ello aplicamos los siguientes filtro y nos muestra la lista de modelos que sirven para clasificar textos en Español.\n",
    "\n",
    "<img src=\"./imgs/031_Modelos_Clsificacion_HgF.png\"/>\n",
    "\n",
    "\n",
    "* Una vez filtrados estos modelos, tenemos que ver cuales nos permiten realizar ***clasificación de textos***, asignando; por ejemplo, una ***polaridad Positiva, Negativa o Neutra***.\n",
    "\n",
    "\n",
    "* Podemos hacer uso del modelo \"https://huggingface.co/finiteautomata/beto-sentiment-analysis\":\n",
    "\n",
    "\n",
    "<img src=\"./imgs/032_Modelo_Clasificacion_HF.png\"/>\n",
    "\n",
    "\n",
    "* Explotar este modelo, sería tan sencillo como indicar en el *pipeline* el modelo seleccionado (finiteautomata/beto-sentiment-analysis) y pasarle unos textos para su predicción:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "979826f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'NEG', 'score': 0.9991390705108643},\n",
       "  {'label': 'NEU', 'score': 0.00025609711883589625},\n",
       "  {'label': 'POS', 'score': 0.0006048274226486683}],\n",
       " [{'label': 'NEG', 'score': 0.0008638024446554482},\n",
       "  {'label': 'NEU', 'score': 0.0005001439130865037},\n",
       "  {'label': 'POS', 'score': 0.9986360669136047}]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "clasificador = pipeline(\"text-classification\", model=\"finiteautomata/beto-sentiment-analysis\")\n",
    "\n",
    "clasificador([\"Este ejemplo muy malo\",\n",
    "              \"Este ejemplo es maravilloso\"],\n",
    "             return_all_scores=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be032a57",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "## 1.2.- Ejemplo: Cálculo de nivel de \"Toxicidad\" de Tweets escritos por políticos.\n",
    "\n",
    "\n",
    "* La conocida empresa *Newtral* ha creado un modelo (basado en RoBERTa) capaz de asignar a un tweet una puntuación de \"toxicidad\".\n",
    "\n",
    "\n",
    "* Este modelo asigna una puntuación de \"Toxic\" (LABEL_0) y \"Very Toxic\" (LABEL_1) a un tweet.\n",
    "\n",
    "\n",
    "* Para construir este modelo han usado un conjunto de tweets escritos por miembros del Congreso de los Diputados, etiquetados cada uno de los tweets con una puntuación de toxicidad.\n",
    "\n",
    "\n",
    "* Los detalles de este modelo están en: https://huggingface.co/Newtral/xlm-r-finetuned-toxic-political-tweets-es\n",
    "\n",
    "\n",
    "<img src=\"./imgs/033_Modelo_toxicidad_tweets_politica_newtral.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf11151f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'LABEL_0', 'score': 0.021804844960570335},\n",
       "  {'label': 'LABEL_1', 'score': 0.006606480106711388}],\n",
       " [{'label': 'LABEL_0', 'score': 0.005288134794682264},\n",
       "  {'label': 'LABEL_1', 'score': 0.0036774096079170704}]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "clasificador = pipeline(\"text-classification\", \n",
    "                        model=\"Newtral/xlm-r-finetuned-toxic-political-tweets-es\")\n",
    "\n",
    "clasificador([\"Es usted un auténtico impresentable, su señoría.\", \n",
    "              \"Es usted un excelente parlamentario, su señoría\"], \n",
    "             return_all_scores=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e0f903",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "# <a name=\"M2\">2.- Traducción</a>\n",
    "\n",
    "\n",
    "* Enlaces de interés para ver el funcionamiento de los transformers en las tareas de traducción: \n",
    "\n",
    "    1. https://towardsdatascience.com/transformers-141e32e69591\n",
    "\n",
    "    2. https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/\n",
    "\n",
    "\n",
    "* Modelo de traducción: https://huggingface.co/Helsinki-NLP/opus-mt-es-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17d65df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXTO EN ESPAÑOL: \n",
      "El Gobierno español sumará a Junqueras las condenas que no vaya a cumplir Puigdemont: Después del revés recibido por el Gobierno de España tras la puesta en libertad de Carles Puigdemont por parte de la justicia alemana, el juez Pablo Llarena ha decidido esta semana, a instancias del Ejecutivo, que sumará a Oriol Junqueras las condenas que no vaya a cumplir el líder del PDeCAT. El exvicepresidente de Cataluña, que permanece en la prisión madrileña de Estremera desde el pasado dos de noviembre, asumiría por tanto todos los delitos atribuidos a Carles Puigdemont y, de esta manera, el Tribunal Supremo se asegura de que los actos del expresidente catalán durante la última legislatura no quedan impunes, ya que “Junqueras pagará por todos y cada uno de ellos”. Con esta maniobra ideada para burlar la justicia alemana, el líder de Esquerra Republicana se enfrenta a 50 años más de prisión. “Seguiremos adelante aunque a Junqueras le caigan cien años más, nadie nos va a parar”, ha dicho hoy Carles Puigdemont desde Alemania. “Haré lo que tenga que hacer y si Junqueras se tiene que sacrificar por ello, lo asumiré con resignación y determinación”, ha prometido. “Seguim!”, tuiteaba poco después de trascender la decisión de Llarena. Según fuentes anónimas del poder judicial, se está barajando también la posibilidad de añadir a la pena de Oriol Junqueras las condenas que puedan imponerse en el futuro a Iñaki Urdangarin, Rodrigo Rato o Esperanza Aguirre, entre otros, así como la de un delito de robo con fuerza ocurrido hace una semana en Huesca y del que la policía ha sido incapaz de encontrar al culpable.\n",
      "\n",
      "TEXTO TRADUCIDO: \n",
      "[{'translation_text': 'The Spanish government will add to Junqueras the sentences that will not fulfill Puigdemont: After the setback received by the government of Spain after the release of Carles Puigdemont by the German justice, Judge Pablo Llarena has decided this week, at the request of the Executive, that it will add to Oriol Junqueras the sentences that the leader of the PDeCAT will not fulfill. The former vice president of Catalonia, who remains in the Madrid prison of Estremera since last two November, would assume therefore all the crimes attributed to Carles Puigdemont and, in this way, the Supreme Court makes sure that the acts of the former president of Catalonia during the last legislature do not go unpunished, since “Junqueras will pay for all and each of them”. With this maneuver designed to mock the German justice, the leader of Esquerra Republicana also sacrifices to the 50 years more of imprisonment. “We will go ahead even if Junqueras falls one hundred more years, no one will stop us”, said today Carles Puigdemont from Germany. “I will do it and Junquera'}]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# Obtenemos un artículo de dataset del \"Mundo Today\"\n",
    "df = pd.read_table('./data/corpus_mundo_today.csv', sep='\\|\\|', header=0, engine='python')\n",
    "text = df.iloc[0]['título'] + ': ' + df.iloc[0]['texto']\n",
    "\n",
    "# Instanciamos el pipeline para la traducción\n",
    "translator = pipeline(\"translation\",\n",
    "                      model=\"Helsinki-NLP/opus-mt-es-en\")\n",
    "\n",
    "# El modelo devuelve la traducción\n",
    "traduction = translator(text)\n",
    "\n",
    "# Imprimimos el texto original y su traducción\n",
    "print('TEXTO EN ESPAÑOL: \\n{}'.format(text))\n",
    "print('\\nTEXTO TRADUCIDO: \\n{}'.format(traduction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b854b9c",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "# <a name=\"M3\">3.- Resumenes de Textos</a>\n",
    "\n",
    "\n",
    "* Modelo para resumenes de textos: https://huggingface.co/csebuetnlp/mT5_multilingual_XLSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "592872f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXTO ORIGINAL: \n",
      "El Gobierno español sumará a Junqueras las condenas que no vaya a cumplir Puigdemont: Después del revés recibido por el Gobierno de España tras la puesta en libertad de Carles Puigdemont por parte de la justicia alemana, el juez Pablo Llarena ha decidido esta semana, a instancias del Ejecutivo, que sumará a Oriol Junqueras las condenas que no vaya a cumplir el líder del PDeCAT. El exvicepresidente de Cataluña, que permanece en la prisión madrileña de Estremera desde el pasado dos de noviembre, asumiría por tanto todos los delitos atribuidos a Carles Puigdemont y, de esta manera, el Tribunal Supremo se asegura de que los actos del expresidente catalán durante la última legislatura no quedan impunes, ya que “Junqueras pagará por todos y cada uno de ellos”. Con esta maniobra ideada para burlar la justicia alemana, el líder de Esquerra Republicana se enfrenta a 50 años más de prisión. “Seguiremos adelante aunque a Junqueras le caigan cien años más, nadie nos va a parar”, ha dicho hoy Carles Puigdemont desde Alemania. “Haré lo que tenga que hacer y si Junqueras se tiene que sacrificar por ello, lo asumiré con resignación y determinación”, ha prometido. “Seguim!”, tuiteaba poco después de trascender la decisión de Llarena. Según fuentes anónimas del poder judicial, se está barajando también la posibilidad de añadir a la pena de Oriol Junqueras las condenas que puedan imponerse en el futuro a Iñaki Urdangarin, Rodrigo Rato o Esperanza Aguirre, entre otros, así como la de un delito de robo con fuerza ocurrido hace una semana en Huesca y del que la policía ha sido incapaz de encontrar al culpable.\n",
      "\n",
      "TEXTO RESUMIDO: \n",
      "[{'summary_text': 'El líder de la oposición catalana, Carles Puigdemont, se enfrenta a 50 años más de prisión.'}]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# Obtenemos un artículo de dataset del \"Mundo Today\"\n",
    "df = pd.read_table('./data/corpus_mundo_today.csv', sep='\\|\\|', header=0, engine='python')\n",
    "text = df.iloc[0]['título'] + ': ' + df.iloc[0]['texto']\n",
    "\n",
    "# Instanciamos el pipeline para el resumen\n",
    "summarizer = pipeline(\"summarization\",\n",
    "                   model=\"csebuetnlp/mT5_multilingual_XLSum\")\n",
    "resumen = summarizer(text)\n",
    "\n",
    "# Imprimimos el texto original y su resumen\n",
    "print('TEXTO ORIGINAL: \\n{}'.format(text))\n",
    "print('\\nTEXTO RESUMIDO: \\n{}'.format(resumen))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8338f3c",
   "metadata": {},
   "source": [
    "* Modelo para resumenes de textos: https://huggingface.co/mrm8488/bert2bert_shared-spanish-finetuned-summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8429ccad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'El exvicepresidente de Cataluña, que permanece en la prisión madrileña de Estremera desde el pasado dos de noviembre, se enfrenta a 50 años más de cárcel'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from transformers import BertTokenizerFast, EncoderDecoderModel\n",
    "\n",
    "# Obtenemos un artículo de dataset del \"Mundo Today\"\n",
    "df = pd.read_table('./data/corpus_mundo_today.csv', sep='\\|\\|', header=0, engine='python')\n",
    "text = df.iloc[0]['título'] + ': ' + df.iloc[0]['texto']\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = BertTokenizerFast.from_pretrained('mrm8488/bert2bert_shared-spanish-finetuned-summarization')\n",
    "model = EncoderDecoderModel.from_pretrained('mrm8488/bert2bert_shared-spanish-finetuned-summarization').to(device)\n",
    "\n",
    "def generate_summary(text):\n",
    "    inputs = tokenizer([text], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    input_ids = inputs.input_ids.to(device)\n",
    "    attention_mask = inputs.attention_mask.to(device)\n",
    "    output = model.generate(input_ids, attention_mask=attention_mask)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "   \n",
    "\n",
    "generate_summary(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0b66c1",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "# <a name=\"M4\">4.- NER (Named Entity Recognition)</a>\n",
    "\n",
    "\n",
    "* Los Modelos de \"Reconocimiento de Entidades Nombradas\" (Token Classification) también se encuentran en Hugging Face.\n",
    "\n",
    "\n",
    "* Veamos a continuación un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41690076",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.99906236,\n",
       "  'word': 'Leo Messi',\n",
       "  'start': 0,\n",
       "  'end': 9},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.997633,\n",
       "  'word': 'Rosario',\n",
       "  'start': 11,\n",
       "  'end': 18},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9976757,\n",
       "  'word': 'Santa Fe',\n",
       "  'start': 20,\n",
       "  'end': 28},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.99919605,\n",
       "  'word': 'FC Barcelona',\n",
       "  'start': 67,\n",
       "  'end': 79},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9945101,\n",
       "  'word': 'Paris Saint - Germain',\n",
       "  'start': 130,\n",
       "  'end': 149}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "ner(\"Leo Messi (Rosario, Santa Fe; 24 de junio de 1987); ex-jugador del FC Barcelona,\"\\\n",
    "    \" esta metiendo pocos goles en su nuevo equipo, el Paris Saint-Germain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dec187",
   "metadata": {},
   "source": [
    "* Un ejemplo de Modelo de NER en Español lo encontramos en: https://huggingface.co/flair/ner-spanish-large.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97a33387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-01 17:57:41,626 loading file C:\\Users\\Usuario\\.flair\\models\\ner-spanish-large\\045ad6c7dc21e0eb85935dce0544eec65f8c63c58412154df4dee7ff5f11665b.d4d3456316d2951bc100d060bd63a690b33af6d273adffa1b90df32328ed3257\n",
      "Sentence: \"Leo Messi ( Rosario , Santa Fe ; 24 de junio de 1987 ) ; ex-jugador del FC Barcelona , esta metiendo pocos goles en su nuevo equipo , el Paris Saint-Germain\"   [− Tokens: 32  − Token-Labels: \"Leo <B-PER> Messi <E-PER> ( Rosario <S-LOC> , Santa <B-LOC> Fe <E-LOC> ; 24 de junio de 1987 ) ; ex-jugador del FC <B-ORG> Barcelona <E-ORG> , esta metiendo pocos goles en su nuevo equipo , el Paris <B-ORG> Saint-Germain <E-ORG>\"]\n",
      "\n",
      "The following NER tags are found:\n",
      "\n",
      "Span [1,2]: \"Leo Messi\"   [− Labels: PER (0.9999)]\n",
      "Span [4]: \"Rosario\"   [− Labels: LOC (0.9999)]\n",
      "Span [6,7]: \"Santa Fe\"   [− Labels: LOC (0.9999)]\n",
      "Span [18,19]: \"FC Barcelona\"   [− Labels: ORG (0.9999)]\n",
      "Span [31,32]: \"Paris Saint-Germain\"   [− Labels: ORG (0.9999)]\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "# load tagger\n",
    "tagger = SequenceTagger.load(\"flair/ner-spanish-large\")\n",
    "\n",
    "# make example sentence\n",
    "sentence = Sentence(\"Leo Messi (Rosario, Santa Fe; 24 de junio de 1987); ex-jugador del FC Barcelona,\"\\\n",
    "                    \" esta metiendo pocos goles en su nuevo equipo, el Paris Saint-Germain\")\n",
    "\n",
    "# predict NER tags\n",
    "tagger.predict(sentence)\n",
    "\n",
    "# print sentence\n",
    "print(sentence)\n",
    "\n",
    "# print predicted NER spans\n",
    "print('\\nThe following NER tags are found:\\n')\n",
    "# iterate over entities and print\n",
    "for entity in sentence.get_spans('ner'):\n",
    "    print(entity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python37_NLP",
   "language": "python",
   "name": "python37_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
