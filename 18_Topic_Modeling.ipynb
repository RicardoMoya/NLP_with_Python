{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18 - Topic Modeling\n",
    "\n",
    "\n",
    "* El ***Topic Modeling*** es una técnica ***no supervisada*** para ***extraer los topics (o temas) ocultos que hay en un corpus***.\n",
    "\n",
    "\n",
    "* Una de las principales aplicaciones del ***NLP*** es la de ***extraer automáticamente los temas*** sobre los que hablan las personas, artículos, tweets, etc. sobre un volumen de textos importante.\n",
    "\n",
    "\n",
    "* Existen diferentes técnicas para ***extraer los topics*** de los corpus, siendo las más conocidas:\n",
    "    1. ***LSI***: Latent Semantic Index\n",
    "    2. ***PLSI***: Probabilistic Latent Semantic Index\n",
    "    3. ***LDA***: Latent Dirichlet Allocation\n",
    "    \n",
    "    \n",
    "* En esencia, la finalidad de estas técnicas es la de extraer una serie de ***factores latentes*** que ***representen tanto a las palabras como a los documentos del corpus*** y a partir de esos factores latentes podremos estudiar:\n",
    "    - Relación entre documentos\n",
    "    - Relación entre palabras\n",
    "    - Extracción de topics (temas)\n",
    "    \n",
    "    \n",
    "* Para ello necesitamos ***representar el copus con una matriz*** (bolsa de palabras) de la siguiente manera:\n",
    "    - ***Filas***: Cada fila representa a un documento.\n",
    "    - ***Columnas***: Cada columnas representa a una palabra.\n",
    "    - ***Celda***: Cada celda representa el número de veces que aparece la palabra en el documento.\n",
    "    \n",
    "    \n",
    "* A partir de la matriz que representa al corpus, tenemos que obtener dos matrices:\n",
    "    1. ***Factores Latentes de las Palabras***\n",
    "    2. ***Factores Latentes de los documentos***\n",
    "    \n",
    "    \n",
    "$$\\begin{bmatrix}\n",
    " &  &  &  &  &  & \\\\ \n",
    " &  &  &  &  &  & \\\\ \n",
    " &  &  & Corpus &  &  & \\\\ \n",
    " &  &  & _{nxm} &  &  & \\\\ \n",
    " &  &  &  &  &  & \n",
    "\\end{bmatrix} =  \\begin{bmatrix}\n",
    "\\: \\\\ \n",
    "\\: \\\\ \n",
    "  Documentos\\\\ \n",
    "  _{nxK}\\\\ \n",
    "\\:\n",
    "\\end{bmatrix} \\cdot \\begin{bmatrix} \n",
    "  Palabras\\\\ \n",
    "  _{Kxm}\\\\ \n",
    "\\end{bmatrix}; \\: siendo \\rightarrow  \\: \\left\\{\\begin{matrix}\n",
    "n: Número \\: de \\: Documentos\\\\ \n",
    "m: Número \\: de \\: Palabras\\\\ \n",
    "K: Número \\: de \\: Factores \\: Latentes\n",
    "\\end{matrix}\\right.$$\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "## Ejemplo:\n",
    "\n",
    "\n",
    "* Veamos a continuación un sencillo ejemplo sobre un copus de 4 documentos:\n",
    "    - ***Doc 1***: _ronaldo _ronaldo _messi balon\n",
    "    - ***Doc 2***: _ronaldo _messi _messi _messi\n",
    "    - ***Doc 3***: gasol gasol triple balon\n",
    "    - ***Doc 4***: triple triple gasol\n",
    "    \n",
    "    \n",
    "* Se puede observar en estos documentos del Corpus que hay dos temáticas diferenciadas que son '*fútbol*' y '*baloncesto*'.\n",
    "\n",
    "\n",
    "* Pasamos a construir la Matrix de frecuencias (BoW) para obtener los factores latentes de los documentos y de las palabras:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_messi</th>\n",
       "      <th>_ronaldo</th>\n",
       "      <th>balon</th>\n",
       "      <th>gasol</th>\n",
       "      <th>triple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc 1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc 2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc 3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc 4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       _messi  _ronaldo  balon  gasol  triple\n",
       "Doc 1       1         2      1      0       0\n",
       "Doc 2       3         1      0      0       0\n",
       "Doc 3       0         0      1      2       1\n",
       "Doc 4       0         0      0      1       2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "documentos = ['_ronaldo _ronaldo _messi balon',\n",
    "             '_ronaldo _messi _messi _messi',\n",
    "             'gasol gasol triple balon',\n",
    "             'triple triple gasol']\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "matrix = vectorizer.fit_transform(documentos)\n",
    "\n",
    "# Resultados\n",
    "pd.DataFrame(matrix.toarray(), index=['Doc 1', 'Doc 2', 'Doc 3', 'Doc 4'], columns=vectorizer.get_feature_names_out()).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtención de los factores latentes\n",
    "\n",
    "\n",
    "* Sin entrar todavía en detalle, vamos a aplicar el SVD (Singular Value Descomposition) a la matriz para obtener los factores latentes de los documentos y las palabras.\n",
    "\n",
    "\n",
    "* Por simplicidad y por tratarse de un caso didáctico, vamos a seleccionar 2 componentes principales.\n",
    "\n",
    "\n",
    "* El SVD, descompone la 'matriz original' en 3 matrices U, S y V.\n",
    "\n",
    "\n",
    "* Para entender el ejemplo vamos a tener:\n",
    "\n",
    "    - ***Factores latentes de los documentos*** = U · S\n",
    "    - ***Factores latentes de las palabras*** = S · V\n",
    "    \n",
    "   \n",
    "<hr>\n",
    "\n",
    "\n",
    "### Factores latentes de los documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Factor 1</th>\n",
       "      <th>Factor 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc 1</th>\n",
       "      <td>2.07</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc 2</th>\n",
       "      <td>3.00</td>\n",
       "      <td>-0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc 3</th>\n",
       "      <td>0.37</td>\n",
       "      <td>2.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc 4</th>\n",
       "      <td>0.18</td>\n",
       "      <td>2.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Factor 1  Factor 2\n",
       "Doc 1      2.07      0.04\n",
       "Doc 2      3.00     -0.43\n",
       "Doc 3      0.37      2.29\n",
       "Doc 4      0.18      2.02"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "svd = TruncatedSVD(n_components=2)\n",
    "U_S = svd.fit_transform(matrix)\n",
    "\n",
    "# Resultados\n",
    "pd.DataFrame(U_S, index=['Doc 1', 'Doc 2', 'Doc 3', 'Doc 4'], columns=['Factor 1', 'Factor 2']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* En los resultados obtenidos, podemos ver:\n",
    "    - Factores latentes de los ***documentos 1 y 2 son similares entre sí***\n",
    "    - Factores latentes de los ***documentos 3 y 4 son similares entre sí***\n",
    "    - Factores latentes de los ***documentos 1 y 2 son diferentes  de los factores latentes de los documentos 3 y 4***.\n",
    "    \n",
    "    \n",
    "* Con estas conclusiones vemos que la hipótesis inicial de que habia dos temas distintos (fútbol y baloncesto) en el corpus es correcta y se pueden diferenciar con los factores latentes que representan a los documentos.\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "### Factores latentes de la palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_messi</th>\n",
       "      <th>_ronaldo</th>\n",
       "      <th>balon</th>\n",
       "      <th>gasol</th>\n",
       "      <th>triple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Factor 1</th>\n",
       "      <td>3.02</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Factor 2</th>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2.14</td>\n",
       "      <td>2.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          _messi  _ronaldo  balon  gasol  triple\n",
       "Factor 1    3.02      1.95   0.67   0.25    0.20\n",
       "Factor 2   -0.41     -0.11   0.76   2.14    2.05"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "V_S = np.dot(np.diag(svd.singular_values_), svd.components_)\n",
    "\n",
    "# Resultados\n",
    "pd.DataFrame(V_S, index=['Factor 1', 'Factor 2'], columns=vectorizer.get_feature_names_out()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* En estos resultados también podemos ver:\n",
    "    - Factores latentes de las ***palabras _messi y _ronaldo son similares entre sí***\n",
    "    - Factores latentes de las ***palabras gasol y triple son similares entre sí***\n",
    "    - Factores latentes de las ***palabras _messi y _ronaldo son diferentes  de los factores latentes de las palabras gasol y triple***.\n",
    "\n",
    "\n",
    "* Con estas conclusiones podemos ver también como las palabras se pueden diferenciar en dos temas distintos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
