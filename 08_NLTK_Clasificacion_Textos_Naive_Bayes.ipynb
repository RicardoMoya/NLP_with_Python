{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08 - NLTK: Clasificación de textos con Naive Bayes\n",
    "\n",
    "* En este notebook vamos a ver como crear un modelo que clasifique las frases según su polaridad (Positiva o Negativa).\n",
    "\n",
    "\n",
    "* Para ello tenemos 3 conjuntos de frases que son:\n",
    "    1. **Positivas**: Conjunto de frases clasificadas con polaridad positiva\n",
    "    2. **Negativas**: Conjunto de frases clasificadas con polaridad negativa\n",
    "    3. **Test**: Conjunto de frases de test a predecir.\n",
    "    \n",
    "\n",
    "* El framework para la clasificación de texto (y para la clasificación en general) es el siguiente:\n",
    "\n",
    "    - ***Entrenamiento***:\n",
    "    \n",
    "        1. Limpieza y ***normalización*** del texto\n",
    "        2. ***Extracción de características***: esto consiste en crear la estructura de datos necesaria para que la utilice el algoritmo de aprendizaje a usar\n",
    "        3. ***Algoritmo de Aprendizaje***: Dado el conjunto de características de los texto y la etiqueta (label) de los textos, el algoritmo de aprendizaje dará como resultado un **modelo**.\n",
    "<br><br>     \n",
    "    - ***Predicción***:\n",
    "    \n",
    "        1. Limpieza y ***normalización*** del texto a clasificar.\n",
    "        2. ***Extracción de características*** del texto a clasificar. Tanto este punto 2 como el anterior (1) deben de realizarse de la misma manera que en la fase de entrenamiento.\n",
    "        3. ***Predicción***: Dado el conjunto de características de los ***texto a predecir*** y el **modelo**, este devolverá la ***clasificación*** (o predicción) del texto.\n",
    "        \n",
    "        \n",
    "* Este framework lo podemos ver en la siguiente imagen:\n",
    "\n",
    "<img src=\"./imgs/009_Clasificacion_framework.png\" style=\"width: 500px;\"/>\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "## Ejemplo con NLTK:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import nltk.classify\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "positive = [('I love this car', 'positive'),\n",
    "            ('This view is amazing', 'positive'),\n",
    "            ('I feel great this morning', 'positive'),\n",
    "            ('I am so excited about the concert', 'positive'),\n",
    "            ('He is my best friend', 'positive'),\n",
    "            ('Going well', 'positive'),\n",
    "            ('Thank you', 'positive'),\n",
    "            ('Hope you are doing well', 'positive'),\n",
    "            ('I am very happy', 'positive'),\n",
    "            ('Good for you', 'positive'),\n",
    "            ('It is all good. I know about it and I accept it.', 'positive'),\n",
    "            ('This is really good!', 'positive'),\n",
    "            ('Tomorrow is going to be fun.', 'positive'),\n",
    "            ('These are great apples today.', 'positive'),\n",
    "            ('How about them apples? Thomas is a happy boy.', 'positive'),\n",
    "            ('I love this sandwich.', 'positive'),\n",
    "            ('This is an amazing place!', 'positive'),\n",
    "            ('I feel very good about these beers.', 'positive'),\n",
    "            ('This is my best work.', 'positive'),\n",
    "            ('What an awesome view', 'positive')]\n",
    "\n",
    "negative = [('I do not like this car', 'negative'),\n",
    "            ('This view is horrible', 'negative'),\n",
    "            ('I feel tired this morning', 'negative'),\n",
    "            ('I am not looking forward to the concert', 'negative'),\n",
    "            ('He is my enemy', 'negative'),\n",
    "            ('I am a bad boy', 'negative'),\n",
    "            ('This is not good', 'negative'),\n",
    "            ('I am bothered by this', 'negative'),\n",
    "            ('I am not connected with this', 'negative'),\n",
    "            ('Sadistic creep you ass. Die.', 'negative'),\n",
    "            ('All sorts of crazy and scary as hell.', 'negative'),\n",
    "            ('Not his emails, no.', 'negative'),\n",
    "            ('His father is dead. Returned obviously.', 'negative'),\n",
    "            ('He has a bomb.', 'negative'),\n",
    "            ('Too fast to be on foot. We cannot catch them.', 'negative'),\n",
    "            ('I do not like this restaurant', 'negative'),\n",
    "            ('I am tired of this stuff.', 'negative'),\n",
    "            (\"I can't deal with this\", 'negative'),\n",
    "            ('He is my sworn enemy!', 'negative'),\n",
    "            ('My boss is horrible.', 'negative')]\n",
    "\n",
    "test = [('I feel happy this morning', 'positive'),\n",
    "        ('Larry is my friend', 'positive'),\n",
    "        ('I do not like that man', 'negative'),\n",
    "        ('My house is not great', 'negative'),\n",
    "        ('Your song is annoying', 'negative'),\n",
    "        ('The beer was good.', 'positive'),\n",
    "        ('I do not enjoy my job', 'negative'),\n",
    "        (\"I feel amazing!\", 'positive'),\n",
    "        ('Gary is a friend of mine.', 'positive'),\n",
    "        (\"I can't believe I'm doing this.\", 'negative')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "## Normalización\n",
    "\n",
    "* En primer lugar vamos a pasar a normalizar las frases. Para ello realizaremos lo siguiente:\n",
    "\n",
    "    - Eliminamos los signos de puntuación\n",
    "    - Eliminamos las Stop-Words\n",
    "    - Pasamos el texto a minúsculas\n",
    "    \n",
    "* Nos creamos una función que realice este procesamiento para las frases dadas.\n",
    "\n",
    "\n",
    "***NOTA***: *Para este ejemplo en particular se hace una normalización muy básica pero suficiente para realizar este ejemplo con caracter didáctico*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(sentenses):\n",
    "    \"\"\"normalizamos la lista de frases\"\"\"\n",
    "    sen = []\n",
    "    for (words, sentiment) in sentenses:\n",
    "        words_filtered = []\n",
    "        for word in words.split():\n",
    "            word = re.sub(r'[^\\w\\s]', '', word).lower() # Eliminamos signos de puntuación y lo pasamos a minúsculas\n",
    "            if len(word) > 2 and word not in stopwords.words(): # Filtramos stop words y las palabras con menos de 3 caracteres\n",
    "                words_filtered.append(word)\n",
    "        sen.append((words_filtered, sentiment))\n",
    "    return sen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "## Extracción de características\n",
    "\n",
    "* El algoritmo de aprendizaje (Naive Bayes) necesita una determina estructura de datos de entrada para generar el modelo. Para ello necesitamos crear:\n",
    "\n",
    "    - Un Diccionario (CUIDADO no es un diccionario python) con todas las palabras del corpus.\n",
    "    \n",
    "    - Una tupla que contenga en la primera posición un Booleano si por cada palabra del diccionario aparece o no la palabra de la frase. El segundo elemento de la tupla es la etiqueta de la frase. \n",
    "    \n",
    "\n",
    "* Para ello creamos las siguientes 2 funciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_words(sentenses):\n",
    "    \"\"\"Función que devuelve una lista con todas las palabras únicas que aparecen en las frases\"\"\"\n",
    "    all_words = []\n",
    "    for (words, sentiment) in sentenses:\n",
    "        all_words.extend(words)\n",
    "    return list(set(all_words))\n",
    "\n",
    "def extract_features(document):\n",
    "    \"\"\"Función que crea el conjunto de entrenamiento del clasificador\n",
    "       1: Toma todos los documentos del corpus\n",
    "       2: Toma todas las palabras del corpus\n",
    "       3: Escribre (True|False) si aparece cada palabra del corpus en la frase\n",
    "    \"\"\"\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in unique_words:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A continuación pasamos a crear el conjunto de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'contains(hope)': False, 'contains(obviously)': False, 'contains(car)': True, 'contains(best)': False, 'contains(apples)': False, 'contains(friend)': False, 'contains(great)': False, 'contains(morning)': False, 'contains(tired)': False, 'contains(bad)': False, 'contains(connected)': False, 'contains(creep)': False, 'contains(bothered)': False, 'contains(hell)': False, 'contains(bomb)': False, 'contains(dead)': False, 'contains(like)': False, 'contains(enemy)': False, 'contains(scary)': False, 'contains(ass)': False, 'contains(tomorrow)': False, 'contains(beers)': False, 'contains(concert)': False, 'contains(place)': False, 'contains(crazy)': False, 'contains(cannot)': False, 'contains(boy)': False, 'contains(cant)': False, 'contains(restaurant)': False, 'contains(catch)': False, 'contains(really)': False, 'contains(horrible)': False, 'contains(sorts)': False, 'contains(well)': False, 'contains(love)': True, 'contains(happy)': False, 'contains(forward)': False, 'contains(feel)': False, 'contains(fast)': False, 'contains(accept)': False, 'contains(sadistic)': False, 'contains(looking)': False, 'contains(thank)': False, 'contains(emails)': False, 'contains(foot)': False, 'contains(sandwich)': False, 'contains(deal)': False, 'contains(father)': False, 'contains(fun)': False, 'contains(excited)': False, 'contains(amazing)': False, 'contains(going)': False, 'contains(know)': False, 'contains(thomas)': False, 'contains(boss)': False, 'contains(good)': False, 'contains(work)': False, 'contains(view)': False, 'contains(stuff)': False, 'contains(sworn)': False, 'contains(returned)': False, 'contains(awesome)': False, 'contains(today)': False}, 'positive')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['love', 'car'], 'positive')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizamos las frases\n",
    "sentenses = normalize(positive+negative)\n",
    "\n",
    "# Obtenemos las palabras del corpus (diccionario del corpus)\n",
    "unique_words = get_unique_words(sentenses)\n",
    "\n",
    "# Construimos el conjunto de entrenamiento\n",
    "training_set = nltk.classify.apply_features(extract_features, sentenses)\n",
    "\n",
    "print(training_set[0])\n",
    "sentenses[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "## Algoritmo de Aprendizaje\n",
    "\n",
    "* Creamos un objeto de la clase NaiveBayesClassifier y llamamos al método train pasándole los datos de entrenamiento.\n",
    "\n",
    "\n",
    "* De esta manera ya tenemos el modelo creado para su uso asi como información relativa al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "## Predicción\n",
    "\n",
    "* Para la predicción vamos a utilizar el modelo creado para ello vamos a:\n",
    "    1. Normalizar las frases\n",
    "    2. Extracción de características de la frase\n",
    "    3. Predicción\n",
    "\n",
    "* Veamos a continuación como hacerlo y como clasificamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase: ['feel', 'happy', 'morning']\n",
      "\tPolaridad: positive - Predicción: positive -> BIEN\n",
      "Frase: ['larry', 'friend']\n",
      "\tPolaridad: positive - Predicción: positive -> BIEN\n",
      "Frase: ['like']\n",
      "\tPolaridad: negative - Predicción: negative -> BIEN\n",
      "Frase: ['house', 'great']\n",
      "\tPolaridad: negative - Predicción: positive -> MAL\n",
      "Frase: ['song', 'annoying']\n",
      "\tPolaridad: negative - Predicción: negative -> BIEN\n",
      "Frase: ['beer', 'good']\n",
      "\tPolaridad: positive - Predicción: positive -> BIEN\n",
      "Frase: ['enjoy', 'job']\n",
      "\tPolaridad: negative - Predicción: negative -> BIEN\n",
      "Frase: ['feel', 'amazing']\n",
      "\tPolaridad: positive - Predicción: positive -> BIEN\n",
      "Frase: ['gary', 'friend']\n",
      "\tPolaridad: positive - Predicción: positive -> BIEN\n",
      "Frase: ['cant', 'believe']\n",
      "\tPolaridad: negative - Predicción: negative -> BIEN\n"
     ]
    }
   ],
   "source": [
    "test = normalize(test)   # Normalizamos\n",
    "for sen in test:\n",
    "    sentense_features = extract_features(sen[0])   # Extracción de características\n",
    "    polarity = classifier.classify(sentense_features)   # Clasificación\n",
    "    print('Frase: ' + str(sen[0]))\n",
    "    print('\\tPolaridad: ' + sen[1] + ' - Predicción: ' + polarity + ' -> ' + ('BIEN' if polarity==sen[1] else 'MAL'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "# Modelo\n",
    "\n",
    "* Veamos a continuación algunas características del modelo:\n",
    "\n",
    "\n",
    "* Podemo ver por ejemplo la probabilidad de que una frase pertenezca a una etiqueta (label):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> P(positivo) = 0.5\n",
      "-> P(negativo) = 0.5\n"
     ]
    }
   ],
   "source": [
    "prob_positive = classifier._label_probdist.prob('positive')\n",
    "prob_negative =  classifier._label_probdist.prob('negative')\n",
    "print ('-> P(positivo) = ' + str(prob_positive))\n",
    "print ('-> P(negativo) = ' + str(prob_negative))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Otra cosa que podemos ver es como de relevante son las palabras que se han utilizado para construir el modelo en función de la etiqueta.\n",
    "\n",
    "\n",
    "* Vemos por ejemplo que si la palabra \"good\" aparece en una frase (*contains(good) = True*), esta frase tiene 3 veces más probabilidades de clasificarse como positiva que como negativa. Esta cálculo (según el código) lo hacen de la siguiente manera:\n",
    "\n",
    "\n",
    "$$positi : negati = \\frac{P(good|positivo)}{P(good|negativo)}$$\n",
    "\n",
    "$$negati : positi = \\frac{P(good|negativo)}{P(good|positivo)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "          contains(good) = True           positi : negati =      3.0 : 1.0\n",
      "          contains(feel) = True           positi : negati =      1.7 : 1.0\n",
      "          contains(view) = True           positi : negati =      1.7 : 1.0\n",
      "          contains(good) = False          negati : positi =      1.2 : 1.0\n",
      "          contains(love) = False          negati : positi =      1.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Podemos ver tambien como calcula el peso para determinar si una frase es positiva o negativa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción: positive\n",
      "{'positive': -0.1526530828020789, 'negative': -3.316091331221193}\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo POSITIVO\n",
    "t = \"I feel happy this morning\"\n",
    "print ('Predicción: ' + classifier.classify(extract_features(t.split())))\n",
    "print (classifier.prob_classify(extract_features(t.split()))._prob_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción: negative\n",
      "{'positive': -2.8112705203211146, 'negative': -0.22174085358772722}\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo NEGATIVO\n",
    "t = \"I do not like that man\"\n",
    "print ('Predicción: ' + classifier.classify(extract_features(t.split())))\n",
    "print (classifier.prob_classify(extract_features(t.split()))._prob_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Por último podemos ver la probabilidad de que una frase se clasifique como positiva o negativa en función de que aparezca o no una determinada palabra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidad de que la frase sea NEGATIVA si APARECE la palabra 'good':\n",
      "0.07142857142857142\n",
      "\n",
      "Probabilidad de que la frase sea POSITIVA si APARECE la palabra 'good':\n",
      "0.21428571428571427\n",
      "\n",
      "Probabilidad de que la frase sea NEGATIVA si NO APARECE la palabra 'good':\n",
      "0.9285714285714286\n",
      "\n",
      "Probabilidad de que la frase sea POSITIVA si NO APARECE la palabra 'good':\n",
      "0.7857142857142857\n"
     ]
    }
   ],
   "source": [
    "print(\"Probabilidad de que la frase sea NEGATIVA si APARECE la palabra 'good':\")\n",
    "print (classifier._feature_probdist[('negative', 'contains(good)')].prob(True))\n",
    "\n",
    "print(\"\\nProbabilidad de que la frase sea POSITIVA si APARECE la palabra 'good':\")\n",
    "print (classifier._feature_probdist[('positive', 'contains(good)')].prob(True))\n",
    "\n",
    "print(\"\\nProbabilidad de que la frase sea NEGATIVA si NO APARECE la palabra 'good':\")\n",
    "print (classifier._feature_probdist[('negative', 'contains(good)')].prob(False))\n",
    "\n",
    "print(\"\\nProbabilidad de que la frase sea POSITIVA si NO APARECE la palabra 'good':\")\n",
    "print (classifier._feature_probdist[('positive', 'contains(good)')].prob(False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
