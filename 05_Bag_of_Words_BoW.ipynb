{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# 05 - Bag of Words (BoW) - Bolsa de Palabras\n",
    "\n",
    "* La Bolsa de Palabras (***BoW***) es un modelo que se utiliza para simplificar el contenido de un documento (o conjunto de documentos) omitiendo la gramática y el orden de las palabras, centrándose solo en el número de ocurrencias de palabras dentro del texto (o corpus).\n",
    "\n",
    "\n",
    "* A continuación se muestra con código python como obtendríamos una bolsa de palabras a partir del siguiente \"corpus\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "documents = [\"balon balon balon futbol futbol liga liga liga ronaldo ronaldo ronaldo messi\",\n",
    "            \"futbol futbol futbol futbol futbol ronaldo ronaldo ronaldo ronaldo messi messi\",\n",
    "            \"balon balon futbol futbol futbol futbol futbol futbol messi messi messi messi\",\n",
    "            \"politica politica politica pp pp pp pp pp pp rajoy rajoy rajoy rajoy rajoy\",\n",
    "            \"politica politica politica politica pp pp psoe psoe psoe psoe zapatero zapatero rajoy\",\n",
    "            \"politica politica politica psoe psoe psoe psoe zapatero zapatero zapatero zapatero \",\n",
    "            \"dinero fmi fmi fmi fmi fmi ue ue ue ue pib pib pib ibex ibex\",\n",
    "            \"zapatero rajoy dinero dinero dinero dinero fmi fmi fmi fmi ue ue ue ue pib\",\n",
    "            \"pp psoe zapatero rajoy dinero dinero dinero dinero fmi fmi fmi fmi ue ue ue \",\n",
    "            \"futbol politica pib\",\n",
    "            \"futbol liga politica zapatero rajoy\"]\n",
    "\n",
    "# Construimos la bolsa de palabras\n",
    "bow = dict()\n",
    "for doc in documents:\n",
    "    doc = doc.split(' ')\n",
    "    for word in doc:\n",
    "        if word in bow:\n",
    "            bow[word] += 1\n",
    "        else:\n",
    "            bow[word] = 1\n",
    "print(bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "* La construcción de las bolsas de palabras no solo se centran en la frecuencia si no que existen otras maneras de asignar un \"peso\" o \"importancia\" dentro del documento o del corpus a las palabras.\n",
    "\n",
    "\n",
    "* Aunque existen más formas de construir bolsas de palabras, las más utilizadas son las siguiente:\n",
    "\n",
    "    1. Vectores de Frecuencias\n",
    "    2. One-Hot-Encode\n",
    "    3. Term Frequency-Inverse Document Frequency (TF-IDF)\n",
    "    \n",
    "    \n",
    "* Veamos a continuación como implementar estas bolsas de palabras con las siguientes librerías:\n",
    "\n",
    "    * ***scikit***\n",
    "    * ***NLTK***\n",
    "    * ***Gensim***\n",
    "    \n",
    "    \n",
    "<hr>\n",
    "\n",
    "\n",
    "# 1.- Vectores de Frecuencias\n",
    "\n",
    "* Los ***vectores de frecuencias*** es el método más trivial de construir las ***Bolsas de Palabras***.\n",
    "\n",
    "\n",
    "* Simplemente consiste en contar cuantas veces aparece una palabra en el documento del corpus.\n",
    "\n",
    "\n",
    "### -Scikit\n",
    "\n",
    "* Esta librería devuelve una matriz en la que las **filas representan a cada documento del corpus** y las **columnas el número de apariciones de las palabras**.\n",
    "\n",
    "\n",
    "* Para saber que palabra corresponde a cada columan de la matriz, scikit nos devuelve una lista en la que coinciden los indice de cada una de las palabras de la lista con la matriz.\n",
    "\n",
    "\n",
    "* Para más información ver el siguiente enlace: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['balon', 'dinero', 'fmi', 'futbol', 'ibex', 'liga', 'messi', 'pib', 'politica', 'pp', 'psoe', 'rajoy', 'ronaldo', 'ue', 'zapatero']\n",
      "[[3 0 0 2 0 3 1 0 0 0 0 0 3 0 0]\n",
      " [0 0 0 5 0 0 2 0 0 0 0 0 4 0 0]\n",
      " [2 0 0 6 0 0 4 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 3 6 0 5 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 4 2 4 1 0 0 2]\n",
      " [0 0 0 0 0 0 0 0 3 0 4 0 0 0 4]\n",
      " [0 1 5 0 2 0 0 3 0 0 0 0 0 4 0]\n",
      " [0 4 4 0 0 0 0 1 0 0 0 1 0 4 1]\n",
      " [0 4 4 0 0 0 0 0 0 1 1 1 0 3 1]\n",
      " [0 0 0 1 0 0 0 1 1 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 1 0 0 1 0 0 1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectors = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Resultados\n",
    "print(vectorizer.get_feature_names())\n",
    "print(vectors.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### -NLTK\n",
    "\n",
    "* NLTK trabajar con diccionarios (un diccionario por documento) cuyas claves son las palabras y los valores son el número de apariciones de esa palabra en el documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'balon': 3, 'futbol': 2, 'liga': 3, 'ronaldo': 3, 'messi': 1})\n",
      "defaultdict(<class 'int'>, {'futbol': 5, 'ronaldo': 4, 'messi': 2})\n",
      "defaultdict(<class 'int'>, {'balon': 2, 'futbol': 6, 'messi': 4})\n",
      "defaultdict(<class 'int'>, {'politica': 3, 'pp': 6, 'rajoy': 5})\n",
      "defaultdict(<class 'int'>, {'politica': 4, 'pp': 2, 'psoe': 4, 'zapatero': 2, 'rajoy': 1})\n",
      "defaultdict(<class 'int'>, {'politica': 3, 'psoe': 4, 'zapatero': 4})\n",
      "defaultdict(<class 'int'>, {'dinero': 1, 'fmi': 5, 'ue': 4, 'pib': 3, 'ibex': 2})\n",
      "defaultdict(<class 'int'>, {'zapatero': 1, 'rajoy': 1, 'dinero': 4, 'fmi': 4, 'ue': 4, 'pib': 1})\n",
      "defaultdict(<class 'int'>, {'pp': 1, 'psoe': 1, 'zapatero': 1, 'rajoy': 1, 'dinero': 4, 'fmi': 4, 'ue': 3})\n",
      "defaultdict(<class 'int'>, {'futbol': 1, 'politica': 1, 'pib': 1})\n",
      "defaultdict(<class 'int'>, {'futbol': 1, 'liga': 1, 'politica': 1, 'zapatero': 1, 'rajoy': 1})\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from collections import defaultdict\n",
    "\n",
    "def tokenize(text):\n",
    "    for token in nltk.word_tokenize(text):\n",
    "        yield token\n",
    "\n",
    "def vectorize(corpus):\n",
    "    features = defaultdict(int)\n",
    "    for token in tokenize(corpus):\n",
    "        features[token] += 1\n",
    "    return features\n",
    "\n",
    "vectors = map(vectorize, documents)\n",
    "\n",
    "# Resultados\n",
    "for v in vectors:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "### -Gensim\n",
    "\n",
    "* ***Gensim trabaja con \"Diccionarios\"*** (gensim.corpora.Dictionary) que es una estructura de datos en la que guarda el orden de las palabras que hay en el corpus.\n",
    "\n",
    "\n",
    "* Posteriormente se construye la Bolsa de Palabras con las frecuencias con la función \"***doc2bow***\"\n",
    "\n",
    "\n",
    "* Como resultado devuelve una lista por cada documento en la que se indicida por cada palabra del documento identificada por el 'id' del diccionario previamente construido la frecuencia de esa palabra en el documento.\n",
    "\n",
    "\n",
    "* Para más información ver el siguiente enlace: https://radimrehurek.com/gensim/corpora/dictionary.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diccionario de palabras -> palabra: frecuencia\n",
      "\n",
      "{'balon': 0, 'futbol': 1, 'liga': 2, 'messi': 3, 'ronaldo': 4, 'politica': 5, 'pp': 6, 'rajoy': 7, 'psoe': 8, 'zapatero': 9, 'dinero': 10, 'fmi': 11, 'ibex': 12, 'pib': 13, 'ue': 14}\n",
      "\n",
      "Apariciones de las palabras en los documentos:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[(0, 3), (1, 2), (2, 3), (3, 1), (4, 3)],\n",
       " [(1, 5), (3, 2), (4, 4)],\n",
       " [(0, 2), (1, 6), (3, 4)],\n",
       " [(5, 3), (6, 6), (7, 5)],\n",
       " [(5, 4), (6, 2), (7, 1), (8, 4), (9, 2)],\n",
       " [(5, 3), (8, 4), (9, 4)],\n",
       " [(10, 1), (11, 5), (12, 2), (13, 3), (14, 4)],\n",
       " [(7, 1), (9, 1), (10, 4), (11, 4), (13, 1), (14, 4)],\n",
       " [(6, 1), (7, 1), (8, 1), (9, 1), (10, 4), (11, 4), (14, 3)],\n",
       " [(1, 1), (5, 1), (13, 1)],\n",
       " [(1, 1), (2, 1), (5, 1), (7, 1), (9, 1)]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import gensim\n",
    "\n",
    "tokenize = [nltk.word_tokenize(text) for text in documents]\n",
    "dictionary = gensim.corpora.Dictionary(tokenize)\n",
    "vectors = [dictionary.doc2bow(token) for token in tokenize]\n",
    "\n",
    "# Resultados\n",
    "print('Diccionario de palabras -> palabra: frecuencia\\n')\n",
    "print(dictionary.token2id)\n",
    "print('\\nApariciones de las palabras en los documentos:')\n",
    "vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "# 2.- One-Hot-Encode\n",
    "\n",
    "* Este método de construcción de la ***Bolsa de Palabras*** consiste en indicar con un flag ([0,1], [True, False], etc.) si una palabra aparece o no en el documento.\n",
    "\n",
    "\n",
    "### -Scikit\n",
    "\n",
    "* Las estructuras de datos de salida de ***Scikit*** son iguales de en el caso de la construcción del vector de frecuencias salvo que en el contenido de la matriz solo hay ceros y unos.\n",
    "\n",
    "\n",
    "* Para más información ver el siguiente enlace: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Binarizer.html#sklearn.preprocessing.Binarizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['balon', 'dinero', 'fmi', 'futbol', 'ibex', 'liga', 'messi', 'pib', 'politica', 'pp', 'psoe', 'rajoy', 'ronaldo', 'ue', 'zapatero']\n",
      "[[1 0 0 1 0 1 1 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 1 0 0 1 0 0 0 0 0 1 0 0]\n",
      " [1 0 0 1 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 1 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 1 1 1 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 1 0 1 0 0 0 1]\n",
      " [0 1 1 0 1 0 0 1 0 0 0 0 0 1 0]\n",
      " [0 1 1 0 0 0 0 1 0 0 0 1 0 1 1]\n",
      " [0 1 1 0 0 0 0 0 0 1 1 1 0 1 1]\n",
      " [0 0 0 1 0 0 0 1 1 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 1 0 0 1 0 0 1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "corpus = vectorizer.fit_transform(documents)\n",
    "\n",
    "onehot = Binarizer()\n",
    "corpus = onehot.fit_transform(corpus.toarray())\n",
    "\n",
    "# Resultados\n",
    "print(vectorizer.get_feature_names())\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "### -NLTK\n",
    "\n",
    "* La estructura de datos de salida de ***NLTK*** es la misma que en el caso de la construcción del vector de frecuencias salvo que los valores del diccionario son ***booleanos*** en vez de numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'balon': True, 'futbol': True, 'liga': True, 'ronaldo': True, 'messi': True}\n",
      "{'futbol': True, 'ronaldo': True, 'messi': True}\n",
      "{'balon': True, 'futbol': True, 'messi': True}\n",
      "{'politica': True, 'pp': True, 'rajoy': True}\n",
      "{'politica': True, 'pp': True, 'psoe': True, 'zapatero': True, 'rajoy': True}\n",
      "{'politica': True, 'psoe': True, 'zapatero': True}\n",
      "{'dinero': True, 'fmi': True, 'ue': True, 'pib': True, 'ibex': True}\n",
      "{'zapatero': True, 'rajoy': True, 'dinero': True, 'fmi': True, 'ue': True, 'pib': True}\n",
      "{'pp': True, 'psoe': True, 'zapatero': True, 'rajoy': True, 'dinero': True, 'fmi': True, 'ue': True}\n",
      "{'futbol': True, 'politica': True, 'pib': True}\n",
      "{'futbol': True, 'liga': True, 'politica': True, 'zapatero': True, 'rajoy': True}\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "def tokenize(text):\n",
    "    for token in nltk.word_tokenize(text):\n",
    "        yield token\n",
    "\n",
    "def vectorize(corpus):\n",
    "    return {token: True for token in tokenize(corpus)}\n",
    "\n",
    "vectors = map(vectorize, documents)\n",
    "\n",
    "# Resultados\n",
    "for v in vectors:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "### -Gensim\n",
    "\n",
    "* La estructura de datos de salida de ***Gensim*** es la misma que en el caso de la construcción de la Bolsa de Palabras de frecuencias salvo que los valores de las palabras en los documentos solo tendrán valor '1'.\n",
    "\n",
    "\n",
    "* Para más información ver el siguiente enlace: https://radimrehurek.com/gensim/corpora/dictionary.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diccionario de palabras -> palabra: id\n",
      "\n",
      "{'balon': 0, 'futbol': 1, 'liga': 2, 'messi': 3, 'ronaldo': 4, 'politica': 5, 'pp': 6, 'rajoy': 7, 'psoe': 8, 'zapatero': 9, 'dinero': 10, 'fmi': 11, 'ibex': 12, 'pib': 13, 'ue': 14}\n",
      "\n",
      "Apariciones de las palabras en los documentos (id, 1):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)],\n",
       " [(1, 1), (3, 1), (4, 1)],\n",
       " [(0, 1), (1, 1), (3, 1)],\n",
       " [(5, 1), (6, 1), (7, 1)],\n",
       " [(5, 1), (6, 1), (7, 1), (8, 1), (9, 1)],\n",
       " [(5, 1), (8, 1), (9, 1)],\n",
       " [(10, 1), (11, 1), (12, 1), (13, 1), (14, 1)],\n",
       " [(7, 1), (9, 1), (10, 1), (11, 1), (13, 1), (14, 1)],\n",
       " [(6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (14, 1)],\n",
       " [(1, 1), (5, 1), (13, 1)],\n",
       " [(1, 1), (2, 1), (5, 1), (7, 1), (9, 1)]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import gensim\n",
    "\n",
    "tokenize = [nltk.word_tokenize(text) for text in documents]\n",
    "dictionary = gensim.corpora.Dictionary(tokenize)\n",
    "vectors = [[(token[0], 1) for token in dictionary.doc2bow(doc)] for doc in tokenize]\n",
    "\n",
    "# Resultados\n",
    "print('Diccionario de palabras -> palabra: id\\n')\n",
    "print(dictionary.token2id)\n",
    "print('\\nApariciones de las palabras en los documentos (id, 1):')\n",
    "vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "# 3.- Term Frequency-Inverse Document Frequency (TF-IDF)\n",
    "\n",
    "\n",
    "* El TF-IDF (Frecuencia de Termino - Frecuencia Inversa de Documento) es una medida numérica que permite expresar como de relevante es una palabra para un documento en una colección de documentos (o corpus).\n",
    "\n",
    "\n",
    "* Construir la Bolsa de Palabras con TF-IDF en vez de con frecuencias evita dar \"importancia\" a texto muy largos y con mucha repetición de palabras, frente a textos cortos y con pocas repeticiones de palabras.\n",
    "\n",
    "\n",
    "* La media de ***TF-IDF*** tiene dos componentes que son:\n",
    "    \n",
    "    * ***TF*** (Term Frecuency): Es la frecuencia con la que aparece la palabra en un documento del corpus. Esta se define como:\n",
    "    \n",
    "    $$tf(t,d) = 1 + log(f_{t,d})$$\n",
    "    \n",
    "    * ***IDF*** (Inverse Document Frequency): La frecuencia inversa del documento nos indica lo común que es una palabra en el corpus.\n",
    "    \n",
    "    $$idf(t,D) = log(1 + \\frac{N}{n_t})$$\n",
    "    \n",
    "\n",
    "* ***TF-IDF*** queda definido como:\n",
    "$$tfidf(t,d,D) = tf(t,d) \\cdot idf(t,D)$$\n",
    "\n",
    "\n",
    "\n",
    "### Ejemplos:\n",
    "\n",
    "* Veamos un ejemplo dado el siguiente corpus de 2 documentos con las siguientes palabras:\n",
    "\n",
    "```\n",
    "corpus = [\"messi messi messi ronaldo ronaldo balon\",\n",
    "          \"messi ronaldo futbol futbol futbol\"]\n",
    "```\n",
    "\n",
    "* ***Ejemplo 1***: Calculamos el ***tf-idf*** de la palabra \"**messi**\" para el documento 1:\n",
    "    \n",
    "    * ***TF***:\n",
    "        - t: número de veces que aparece la palabra \"messi\" en el documento 1 -> 3\n",
    "        - d: número de palabras que tiene el documento 1 -> 6\n",
    "        $$tf(t,d) = 1 + log(\\frac{3}{6}) =  0,69$$\n",
    "        \n",
    "    * ***IDF***:\n",
    "        - n<sub>t</sub>: número de documentos en los que aparece la palabra 'messi' -> 2\n",
    "        - D: número total de documentos en el corpus -> 2\n",
    "        $$idf(t,D) = log(1 + \\frac{2}{2}) = 0,3$$\n",
    "        \n",
    "    * ***TF-IDF***:\n",
    "    $$tfidf(t,d,D) = tf(t,d) \\cdot idf(t,D) = 0,69 * 0,3 = 0,21$$\n",
    "    \n",
    "    \n",
    "* ***Ejemplo 2***: Calculamos el ***tf-idf*** de la palabra \"**futbol**\" para el documento 2:\n",
    "    \n",
    "    * ***TF***:\n",
    "        - t: número de veces que aparece la palabra \"futbol\" en el documento 2 -> 3\n",
    "        - d: número de palabras que tiene el documento 1 -> 5\n",
    "        $$tf(t,d) = 1 + log(\\frac{3}{5}) =  0,78$$\n",
    "        \n",
    "    * ***IDF***:\n",
    "        - n<sub>t</sub>: número de documentos en los que aparece la palabra 'futbol' -> 1\n",
    "        - D: número total de documentos en el corpus -> 2\n",
    "        $$idf(t,D) = log(1 + \\frac{2}{1}) = 0,48$$\n",
    "        \n",
    "    * ***TF-IDF***:\n",
    "    $$tfidf(t,d,D) = tf(t,d) \\cdot idf(t,D) = 0,78 * 0,48 = 0,37$$\n",
    "        \n",
    "\n",
    "## Implementación:\n",
    "\n",
    "\n",
    "* El ejemplo mostrado anteriormente se ha realizado sobre el un TF-IDF teórico, calculando la frecuencia escalada logaritmicamente y sobre un corpus de \"juguete\" para entender el concepto.\n",
    "\n",
    "\n",
    "* Las implementaciones del ***TF-IDF*** de **Scikit** y **Gensim** estan pensadas para corpus con un número relevante de documentos y de palabras, por tanto la implementación del ***TF-IDF*** acepta una serie de parámetros para no tener en cuenta Stop Words, palabras irrelevantes, etc. por lo que si se realiza una implementación del ***TF-IDF*** según la bibliografia no van a conincidir los resultados de esa implementación con los resultados de las librerías de **Scikit** y **Gensim** a no ser que se modifiquen los parámetros de las funciones del ***TF-IDF***.\n",
    "\n",
    "\n",
    "### -Scikit\n",
    "\n",
    "* Las estructuras de datos de salida de ***Scikit*** son iguales de en el caso de la construcción del vector de frecuencias salvo que en el contenido de la matriz será de números decimales en vez de números enteros.\n",
    "\n",
    "\n",
    "* Para más información ver el siguiente enlace: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['balon', 'dinero', 'fmi', 'futbol', 'ibex', 'liga', 'messi', 'pib', 'politica', 'pp', 'psoe', 'rajoy', 'ronaldo', 'ue', 'zapatero']\n",
      "[[0.54967598 0.         0.         0.26000769 0.         0.54967598\n",
      "  0.16113642 0.         0.         0.         0.         0.\n",
      "  0.54967598 0.         0.        ]\n",
      " [0.         0.         0.         0.63030611 0.         0.\n",
      "  0.31249927 0.         0.         0.         0.         0.\n",
      "  0.71067462 0.         0.        ]\n",
      " [0.34051088 0.         0.         0.72480795 0.         0.\n",
      "  0.59892051 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.31745291 0.78694939 0.         0.52908818\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.55616781 0.34467783 0.68935567 0.13904195\n",
      "  0.         0.         0.27808391]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.4260541  0.         0.70411076 0.\n",
      "  0.         0.         0.56807213]\n",
      " [0.         0.13121747 0.65608737 0.         0.34911415 0.\n",
      "  0.         0.39365242 0.         0.         0.         0.\n",
      "  0.         0.5248699  0.        ]\n",
      " [0.         0.5639857  0.5639857  0.         0.         0.\n",
      "  0.         0.14099642 0.         0.         0.         0.11375503\n",
      "  0.         0.5639857  0.11375503]\n",
      " [0.         0.60096496 0.60096496 0.         0.         0.\n",
      "  0.         0.         0.         0.15024124 0.15024124 0.12121369\n",
      "  0.         0.45072372 0.12121369]\n",
      " [0.         0.         0.         0.53177225 0.         0.\n",
      "  0.         0.659118   0.53177225 0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.40871302 0.         0.57603355\n",
      "  0.         0.         0.40871302 0.         0.         0.40871302\n",
      "  0.         0.         0.40871302]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "corpus = tfidf.fit_transform(documents)\n",
    "\n",
    "# Resultados\n",
    "print(tfidf.get_feature_names())\n",
    "print(corpus.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "### -Gensim\n",
    "\n",
    "* La estructura de datos de salida de ***Gensim*** es la misma que en el caso de la construcción de la Bolsa de Palabras de frecuencias salvo que los valores de las palabras en los documentos tendrán números decimales en vez de números enteros.\n",
    "\n",
    "\n",
    "* Para más información ver el siguiente enlace: https://radimrehurek.com/gensim/models/tfidfmodel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diccionario de palabras -> palabra: id\n",
      "\n",
      "{'balon': 0, 'futbol': 1, 'liga': 2, 'messi': 3, 'ronaldo': 4, 'politica': 5, 'pp': 6, 'rajoy': 7, 'psoe': 8, 'zapatero': 9, 'dinero': 10, 'fmi': 11, 'ibex': 12, 'pib': 13, 'ue': 14}\n",
      "\n",
      "Apariciones de las palabras en los documentos (id, tfidf):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[(0, 0.5625782665647677),\n",
       "  (1, 0.17346413313634462),\n",
       "  (2, 0.5625782665647677),\n",
       "  (3, 0.14292402346071878),\n",
       "  (4, 0.5625782665647677)],\n",
       " [(1, 0.4753096556596214), (3, 0.3133012785909152), (4, 0.8221453886448734)],\n",
       " [(0, 0.4364883596941802), (1, 0.6056363309296559), (3, 0.6653439309932482)],\n",
       " [(5, 0.2613558865696037), (6, 0.8613661899618252), (7, 0.43559314428267276)],\n",
       " [(5, 0.46092812545169537),\n",
       "  (6, 0.3797770814326364),\n",
       "  (7, 0.11523203136292384),\n",
       "  (8, 0.7595541628652728),\n",
       "  (9, 0.23046406272584768)],\n",
       " [(5, 0.3626105786520071), (8, 0.7967182135514425), (9, 0.4834807715360095)],\n",
       " [(10, 0.12439479522615843),\n",
       "  (11, 0.6219739761307922),\n",
       "  (12, 0.4591543106110927),\n",
       "  (13, 0.3731843856784753),\n",
       "  (14, 0.4975791809046337)],\n",
       " [(7, 0.08604721233664431),\n",
       "  (9, 0.08604721233664431),\n",
       "  (10, 0.5671818639333573),\n",
       "  (11, 0.5671818639333573),\n",
       "  (13, 0.14179546598333934),\n",
       "  (14, 0.5671818639333573)],\n",
       " [(6, 0.1512091023340141),\n",
       "  (7, 0.09175978685592859),\n",
       "  (8, 0.1512091023340141),\n",
       "  (9, 0.09175978685592859),\n",
       "  (10, 0.6048364093360564),\n",
       "  (11, 0.6048364093360564),\n",
       "  (14, 0.45362730700204235)],\n",
       " [(1, 0.46050649452343395), (5, 0.46050649452343395), (13, 0.758859365761191)],\n",
       " [(1, 0.33952362879716663),\n",
       "  (2, 0.734094559272588),\n",
       "  (5, 0.33952362879716663),\n",
       "  (7, 0.33952362879716663),\n",
       "  (9, 0.33952362879716663)]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import gensim\n",
    "\n",
    "tokenize = [nltk.word_tokenize(text) for text in documents]\n",
    "dictionary = gensim.corpora.Dictionary(tokenize)\n",
    "tfidf = gensim.models.TfidfModel(dictionary=dictionary, normalize=True)\n",
    "vectors = [tfidf[dictionary.doc2bow(doc)] for doc in tokenize]\n",
    "\n",
    "# Resultados\n",
    "print('Diccionario de palabras -> palabra: id\\n')\n",
    "print(dictionary.token2id)\n",
    "print('\\nApariciones de las palabras en los documentos (id, tfidf):')\n",
    "vectors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
