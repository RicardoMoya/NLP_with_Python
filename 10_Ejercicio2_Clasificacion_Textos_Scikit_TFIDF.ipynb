{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 - Ejercicio 2: Clasificación de textos con Scikit-Learn\n",
    "\n",
    "\n",
    "* Este ejercicio es exactamente igual que el notebook \"*09_Scikit_Clasificacion_Textos*\" que consistia en clasificar una serie de Tweets en Ingles sobre críticas a los productos de Apple.\n",
    "\n",
    "\n",
    "* Estos tweets estan clasificados como: *positivos*, *neutros* o *negativos*\n",
    "\n",
    "\n",
    "* En esta caso vamos a realizar un cambio para ver si los resultados de clasificación mejoran o no respecto al notebook \"*09_Scikit_Clasificacion_Textos*\" y este cambio va a consistir en ***cambiar la bolsa de palabras de frecuencias a TF-IDF***\n",
    "\n",
    "\n",
    "* ***El objetivo es ver si con este cambio los resultados obtenidos por los modelos generados son mejores, peores o iguales que los obtenidos anteriormente***\n",
    "\n",
    "\n",
    "* Al igual que en el notebook \"*09_Scikit_Clasificacion_Textos*\" realizaremos los siguientes pasos:\n",
    "    \n",
    "    1. Carga de los datos (tweets)\n",
    "    2. Normalización (en ingles) de los tweets\n",
    "    3. ***Creacción de la Bolsa de Palabras*** - TODO -\n",
    "    4. Particionado de Datos\n",
    "    5. Creacción de modelos\n",
    "        - Multinomial Naive Bayes\n",
    "        - Bernoulli Naive Bayes\n",
    "        - Regresion Logistica\n",
    "        - Support Vector Machine\n",
    "        - Random Forest\n",
    "    6. Evaluación de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "## Carga de Datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tweets_file = './data/Apple_Tweets.csv'\n",
    "df = pd.read_csv(tweets_file, header=None)\n",
    "tweets = [tuple(x) for x in df.values]\n",
    "print('Número de Tweets Cargados: {num}'.format(num=len(tweets)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "## Normalización\n",
    "\n",
    "* Para ***normalizar*** los tweets realizaremos las siguientes acciones:\n",
    "    1. Pasamos las frases a minúsculas.\n",
    "    2. Eliminamos los signos de puntuación.\n",
    "    3. Eliminamos las palabras con menos de 3 caracteres.\n",
    "    4. Eliminamos las Stop-Words.\n",
    "    5. Eliminamos las palabras que empiecen por '@' o 'http'.\n",
    "    6. Pasamos la palabra a su lema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('es')\n",
    "\n",
    "# Divido los datos en dos listas \n",
    "#     X: los tweets\n",
    "#     y: target (polaridad)\n",
    "\n",
    "X = [doc[0] for doc in tweets]\n",
    "y = [doc[1] for doc in tweets]\n",
    "\n",
    "def normalize(sentenses):\n",
    "    \"\"\"normalizamos la lista de frases y devolvemos la misma lista de frases normalizada\"\"\"\n",
    "    for index, sentense in enumerate(sentenses):\n",
    "        sentense = nlp(sentense.lower()) # Paso la frase a minúsculas y a un objeto de la clase Doc de Spacy\n",
    "        sentenses[index] = \" \".join([word.lemma_ for word in sentense if (not word.is_punct)\n",
    "                                     and (len(word.text) > 2) and (not word.is_stop) \n",
    "                                     and (not word.text.startswith('@')) and (not word.text.startswith('http'))])\n",
    "    return sentenses\n",
    "\n",
    "# Normalizamos las frases\n",
    "X = normalize(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "## Bolsa de Palabras - EJERCICIO -\n",
    "\n",
    "\n",
    "* En este punto hay que construir la bolsa de palabras con el TF-IDF (Ver notebook: \"*05_Bag_of_Words_BoW*\")\n",
    "\n",
    "\n",
    "* Al igual que la implementación de la clase \"*CountVectorizer*\", la clase \"*TfidfVectorizer*\" también permite quedarnos con las palabras más relevantes, utilizando los dos parámetros que son:\n",
    "    - **max_features**: Con este parámetro le indicamos que nos seleccione la '*X*' palabras más frecuentes del corpus. En este ejemplo **seleccionaremos las 1000 más frecuentes**.\n",
    "    - **min_df**: Con este parámetro le indicamos el número mínimo de documentos en la que tiene que aparecer la palabra para que se incluya en la bolsa de palabras. En este ejemplo **seleccionaremos 3 documentos** (tweets).\n",
    "    \n",
    "\n",
    "* ***NOTA***: para más información podéis mirar la documentación de la clase \"*TfidfVectorizer*\" en: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "## Particionado de Datos (Train y Test)\n",
    "\n",
    "* Particionamos de la siguiente manera:\n",
    "\n",
    "    - 80% de datos de entrenamiento\n",
    "    - 20% de datos de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print('Número de Tweets para el entrenamiento: {num}'.format(num=X_train.shape[0]))\n",
    "print('Número de Tweets para el test: {num}'.format(num=X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "## Creacción de los Modelos\n",
    "\n",
    "\n",
    "* Para este ejercicio vamos a usar los siguientes algoritmos de aprendizaje:\n",
    "\n",
    "    - Multinomial Naive Bayes\n",
    "    - Bernoulli Naive Bayes\n",
    "    - Regresion Logistica\n",
    "    - Support Vector Machine\n",
    "    - Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "bnb = BernoulliNB()\n",
    "lr = LogisticRegression(solver='lbfgs', multi_class='multinomial', max_iter=1000)\n",
    "svm = LinearSVC()\n",
    "rf = RandomForestClassifier(max_depth=50, n_estimators=20, max_features=5)\n",
    "\n",
    "clasificadores = {'Multinomial Naive Bayes': mnb,\n",
    "                  'Bernoulli Naive Bayes': bnb,\n",
    "                  'Regresion Logistica': lr,\n",
    "                  'Support Vector Machine': svm,\n",
    "                  'Random Forest': rf}\n",
    "\n",
    "\n",
    "# Ajustamos los modelos y calculamos el accuracy para los datos de entrenamiento\n",
    "for k, v in clasificadores.items():\n",
    "    print ('CREANDO MODELO: {clas}'.format(clas=k))\n",
    "    v.fit(X_train, y_train)\n",
    "    accuracy_train = v.score(X_train, y_train)\n",
    "    print ('\\tAccuracy Train: {acc_train}'.format(acc_train=accuracy_train)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "\n",
    "## Evaluación del Modelo\n",
    "\n",
    "\n",
    "* Para cada uno de los modelos vamos a calcular las siguientes métricas de evaluación:\n",
    "\n",
    "    1. **Accuracy**\n",
    "    2. **F1**\n",
    "    3. **Precision**\n",
    "    4. **Recall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "evaluacion = list()\n",
    "for k, v in clasificadores.items():\n",
    "    print ('EVALUANDO MODELO: {model}'.format(model=k))\n",
    "    model = {}\n",
    "    model['name'] = k\n",
    "    y_pred = v.predict(X_test)\n",
    "    model['accuracy'] = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "    model['f1'] = f1_score(y_true=y_test, y_pred=y_pred, average='weighted')\n",
    "    model['precision'] = precision_score(y_true=y_test, y_pred=y_pred, average='weighted')\n",
    "    model['recall'] = recall_score(y_true=y_test, y_pred=y_pred, average='weighted')\n",
    "    evaluacion.append(model)\n",
    "\n",
    "# Pasamos los resultados a un DataFrame para visualizarlos mejor\n",
    "df = pd.DataFrame.from_dict(evaluacion)\n",
    "df.set_index(\"name\", inplace=True)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
